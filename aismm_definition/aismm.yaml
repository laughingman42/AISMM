# AI Security Maturity Model Configuration
# Version 1.0.0

version: "1.0.0"
name: "AI Security Maturity Model"
description: "Comprehensive model for assessing organizational AI security maturity across three foundational pillars"
created_at: "2025-12-01T00:00:00Z"

# Scoring Configuration
scoring_config:
  version: "1.0.0"
  max_score: 100
  passing_threshold: 75.0
  
  # Level scoring values
  level_scores:
    level_1: 1
    level_2: 2
    level_3: 3
    level_4: 4
    level_5: 5
  
  # Maturity level thresholds (percentage scores)
  maturity_thresholds:
    level_5: 90  # 90% and above = Level 5 (Optimizing)
    level_4: 70  # 70% and above = Level 4 (Managed)
    level_3: 50  # 50% and above = Level 3 (Defined)
    level_2: 30  # 30% and above = Level 2 (Developing)
    level_1: 0   # Below 30% = Level 1 (Initial)

# Pillar Definitions
pillars:
  security_for_ai:
    id: "security_for_ai"
    name: "Security for AI"
    description: "Protecting AI systems, models, and data from threats and vulnerabilities"
    weight: 1.2
    
  ai_for_security:
    id: "ai_for_security"
    name: "AI for Security"
    description: "Leveraging AI capabilities to enhance organizational security operations"
    weight: 1.0
    
  security_from_ai:
    id: "security_from_ai"
    name: "Security from AI"
    description: "Defending against AI-enabled attacks and malicious AI usage"
    weight: 1.1

# Domain Definitions
domains:
  # Security for AI Domains
  ai_security_standards:
    id: "ai_security_standards"
    name: "AI Security Standards"
    description: "Establishment and implementation of comprehensive AI security standards and governance frameworks"
    pillar: "security_for_ai"
    weight: 1.3

    key_controls:
      - "Formal AI governance framework and steering committee"
      - "AI risk appetite definition and risk classification criteria"
      - "Documented AI security policies aligned with enterprise security"
      - "Compliance mapping to NIST AI RMF, ISO 42001, EU AI Act"
      - "Regular policy review and update cycles (quarterly minimum)"
    
    framework_alignment:
      - indicator: "Existence of documented AI security policies and procedures"
        frameworks:
          nist_ai_rmf: ["GOVERN 1.1", "GOVERN 1.3"]
          iso_27001: ["A.5.1.1", "A.5.1.2", "A.12.1.1"]
          iso_42001: ["5.2", "7.5", "8.2.1"]
          mitre_atlas: ["AML.T0034 - Cost Harvesting", "AML.T0047 - ML Supply Chain Compromise"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Governance", "LLM10:2025 Unbounded Consumption - Policy"]
      - indicator: "Compliance with industry standards (NIST AI RMF, ISO/IEC 27001, etc.)"
        frameworks:
          nist_ai_rmf: ["GOVERN 1.2", "GOVERN 2.1"]
          iso_27001: ["A.18.1.1", "A.18.1.2", "Clause 9.2"]
          eu_ai_act: ["Article 17", "Article 9"]
          iso_42001: ["4.1", "9.2", "10.2"]
          mitre_atlas: ["AML.T0034 - Cost Harvesting", "AML.T0047 - ML Supply Chain Compromise"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Governance", "LLM10:2025 Unbounded Consumption - Policy"]
      - indicator: "Regular updates to security standards based on emerging threats"
        frameworks:
          nist_ai_rmf: ["GOVERN 1.6", "MAP 1.5"]
          iso_27001: ["A.12.6.1", "A.16.1.2", "Clause 10.1"]
          iso_42001: ["10.1", "9.3", "8.5.1"]
          mitre_atlas: ["AML.T0034 - Cost Harvesting", "AML.T0047 - ML Supply Chain Compromise"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Governance", "LLM10:2025 Unbounded Consumption - Policy"]
      - indicator: "Integration with existing enterprise security frameworks"
        frameworks:
          iso_27001: ["A.5.1.1", "A.6.1.1", "Clause 4.1"]
          soc2_security: ["CC1.1", "CC3.1", "CC5.1"]
          iso_42001: ["4.1", "5.1", "8.1"]
          mitre_atlas: ["AML.T0034 - Cost Harvesting", "AML.T0047 - ML Supply Chain Compromise"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Governance", "LLM10:2025 Unbounded Consumption - Policy"]
      - indicator: "Measurable security objectives and KPIs"
        frameworks:
          iso_27001: ["Clause 6.2", "Clause 9.1", "A.18.2.1"]
          nist_csf: ["ID.GV-4", "PR.IP-3", "DE.DP-4"]
          soc2_security: ["CC4.1", "CC5.2"]
          iso_42001: ["6.2", "9.1", "9.3"]
    
          mitre_atlas: ["AML.T0034 - Cost Harvesting", "AML.T0047 - ML Supply Chain Compromise"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Governance", "LLM10:2025 Unbounded Consumption - Policy"]
    levels:
      level_1:
        level: "level_1"
        name: "Initial"
        description: "No formal AI security standards exist; security decisions are made reactively"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Developing"
        description: "Basic AI security standards are documented but may not be comprehensive or consistently applied"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Defined"
        description: "Standards are technically implemented with clear procedures and controls"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Managed"
        description: "Standards are supported by dedicated tools and automated capabilities"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Optimizing"
        description: "Standards are robustly implemented across the organization with integrated governance"
        score_value: 5
    
    indicators:
      indicators:
        - "Existence of documented AI security policies and procedures"
        - "Compliance with industry standards (NIST AI RMF, ISO/IEC 27001, etc.)"
        - "Regular updates to security standards based on emerging threats"
        - "Integration with existing enterprise security frameworks"
        - "Measurable security objectives and KPIs"
      
      definitions:
        level_1: "No formal AI security standards exist; security decisions are made reactively"
        level_2: "Basic AI security standards are documented but may not be comprehensive or consistently applied"
        level_3: "Standards are technically implemented with clear procedures and controls"
        level_4: "Standards are supported by dedicated tools and automated capabilities"
        level_5: "Standards are robustly implemented across the organization with integrated governance"
      
      success_criteria:
        - "100% of AI projects follow documented security standards"
        - "Standards are reviewed and updated quarterly"
        - "Compliance metrics are tracked and reported"
        - "Integration with existing governance frameworks"
    
    questions:
      - id: "ai_sec_std_q1"
        text: "Does your organization have documented AI security policies and procedures?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        slider_compatible: true
        options:
          - "No formal AI security policies exist"
          - "Basic AI security policies are documented but incomplete"
          - "Comprehensive AI security policies are documented and regularly updated"
          - "AI security policies are integrated with enterprise security frameworks"
          - "AI security policies are automatically enforced with monitoring and compliance tracking"
        help_text: "Consider whether policies cover AI development, deployment, monitoring, and governance"
      
      - id: "ai_sec_std_q2"
        text: "How well does your organization comply with AI security standards (NIST AI RMF, ISO/IEC 27001, etc.)?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No awareness or compliance with AI security standards"
          - "Basic awareness but limited implementation"
          - "Partial compliance with some standards"
          - "Good compliance with major AI security standards"
          - "Full compliance with multiple standards including regular audits"
        help_text: "Evaluate compliance across development, deployment, and operational phases"
      
      - id: "ai_sec_std_q3"
        text: "How frequently are your AI security standards reviewed and updated?"
        question_type: "single_choice"
        weight: 0.8
        required: true
        options:
          - "Never or very rarely updated"
          - "Updated when major incidents occur"
          - "Annual review and updates"
          - "Quarterly review with updates as needed"
          - "Continuous monitoring with real-time updates"
        help_text: "Consider how well standards adapt to emerging AI threats and technologies"
      
      - id: "ai_sec_std_q4"
        text: "Which AI security frameworks and standards does your organization follow? (Select all that apply)"
        question_type: "multiple_choice"
        weight: 1.0
        required: true
        slider_compatible: false
        options:
          - "NIST AI Risk Management Framework (AI RMF)"
          - "ISO/IEC 27001 with AI security extensions"
          - "OWASP AI Security and Privacy Guide"
          - "IEEE Standards for AI Systems"
          - "Industry-specific AI security frameworks"
          - "Custom internal AI security framework"
          - "No formal frameworks followed"
        help_text: "Select all frameworks and standards that your organization actively follows or implements"
      
      - id: "ai_sec_std_q5"
        text: "Please describe the biggest AI security challenge your organization currently faces and how you are addressing it."
        question_type: "text"
        weight: 0.5
        required: false
        slider_compatible: false
        help_text: "Provide specific details about challenges such as data protection, model security, governance issues, or resource constraints. This helps us understand your unique context."
      
      # Success Criteria Assessment Questions
      - id: "ai_sec_std_sc_q1"
        text: "What percentage of your AI projects currently follow documented security standards?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "0-20% of AI projects follow standards"
          - "21-40% of AI projects follow standards"
          - "41-60% of AI projects follow standards"
          - "61-80% of AI projects follow standards"
          - "81-100% of AI projects follow standards"
        help_text: "Consider all AI projects including development, testing, and production systems"
      
      - id: "ai_sec_std_sc_q2"
        text: "How frequently are your AI security standards reviewed and updated?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "Never or ad-hoc updates only"
          - "Annual reviews"
          - "Semi-annual reviews"
          - "Quarterly reviews (meeting success criteria)"
          - "Monthly or more frequent reviews"
        help_text: "Success criteria target is quarterly review cycles"
      
      - id: "ai_sec_std_sc_q3"
        text: "How comprehensively does your organization track and report compliance metrics for AI security standards?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No systematic tracking of compliance metrics"
          - "Basic tracking with manual reporting"
          - "Structured tracking with periodic reporting"
          - "Comprehensive tracking with regular automated reporting"
          - "Real-time compliance dashboards with continuous reporting"
        help_text: "Evaluate both the comprehensiveness of metrics and frequency of reporting"
      
      - id: "ai_sec_std_sc_q4"
        text: "How well are your AI security standards integrated with existing governance frameworks?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No integration with existing governance frameworks"
          - "Basic alignment with some governance processes"
          - "Partial integration with key governance frameworks"
          - "Well-integrated with most governance frameworks"
          - "Fully integrated across all relevant governance frameworks"
        help_text: "Consider integration with enterprise risk management, compliance, and security governance"

  security_reviews:
    id: "security_reviews"
    name: "Security Reviews"
    description: "Systematic security assessment and review processes for AI systems"
    pillar: "security_for_ai"
    weight: 1.2

    key_controls:
      - "Mandatory security review gates in AI development lifecycle"
      - "Automated security scanning for ML pipelines and models"
      - "Red team assessments for AI systems pre-deployment"
      - "Security review documentation and remediation tracking"
      - "Integration with CI/CD for continuous security validation"
    
    framework_alignment:
      - indicator: "Frequency and consistency of AI security assessments"
        frameworks:
          nist_ai_rmf: ["MEASURE 2.1", "MEASURE 2.2"]
          iso_27001: ["A.14.2.1", "A.14.2.8"]
          nist_csf: ["DE.CM-1", "DE.CM-7"]
          iso_42001: ["9.2", "8.6", "8.7"]
          mitre_atlas: ["AML.T0010 - ML Supply Chain Compromise", "AML.T0042 - Verify Attack"]
          owasp_genai: ["LLM09:2025 Misinformation - Validation", "LLM02:2025 Sensitive Information Disclosure - Testing"]
      - indicator: "Scope and depth of security reviews"
        frameworks:
          nist_ai_rmf: ["MAP 1.1", "MAP 1.2", "MAP 5.1"]
          iso_27001: ["A.14.2.2", "A.14.2.3"]
          owasp_asvs: ["V1.1", "V1.11"]
          iso_42001: ["8.2.2", "8.6", "8.7"]
          mitre_atlas: ["AML.T0010 - ML Supply Chain Compromise", "AML.T0042 - Verify Attack"]
          owasp_genai: ["LLM09:2025 Misinformation - Validation", "LLM02:2025 Sensitive Information Disclosure - Testing"]
      - indicator: "Automation level of security testing"
        frameworks:
          nist_csf: ["PR.IP-1", "DE.CM-4"]
          iso_27001: ["A.14.2.5", "A.14.2.6"]
          soc2_security: ["CC6.1", "CC6.6"]
          iso_42001: ["8.2.2", "8.3"]
          mitre_atlas: ["AML.T0010 - ML Supply Chain Compromise", "AML.T0042 - Verify Attack"]
          owasp_genai: ["LLM09:2025 Misinformation - Validation", "LLM02:2025 Sensitive Information Disclosure - Testing"]
      - indicator: "Integration with development lifecycle"
        frameworks:
          nist_csf: ["PR.IP-2", "ID.SC-1"]
          iso_27001: ["A.14.1.1", "A.14.2.1"]
          nist_ssdf: ["PO.3.1", "PO.3.2"]
          iso_42001: ["8.2", "8.3", "8.4"]
          mitre_atlas: ["AML.T0010 - ML Supply Chain Compromise", "AML.T0042 - Verify Attack"]
          owasp_genai: ["LLM09:2025 Misinformation - Validation", "LLM02:2025 Sensitive Information Disclosure - Testing"]
      - indicator: "Policy enforcement mechanisms"
        frameworks:
          nist_ai_rmf: ["GOVERN 3.1", "GOVERN 3.2"]
          iso_27001: ["A.13.1.3", "A.18.1.4"]
          soc2_security: ["CC5.1", "CC5.3"]
          iso_42001: ["5.2", "8.1", "8.5.2"]
    
          mitre_atlas: ["AML.T0010 - ML Supply Chain Compromise", "AML.T0042 - Verify Attack"]
          owasp_genai: ["LLM09:2025 Misinformation - Validation", "LLM02:2025 Sensitive Information Disclosure - Testing"]
    levels:
      level_1:
        level: "level_1"
        name: "Ad-hoc Reviews"
        description: "Security reviews happen sporadically without formal process"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Structured Reviews"
        description: "Structured review process with defined criteria and documentation"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Automated Reviews"
        description: "Automated tools perform regular security assessments for AI-specific risks"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Enhanced Automation"
        description: "Enhanced automation with comprehensive AI risk and vulnerability coverage"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Policy Enforcement"
        description: "Automated policy enforcement with real-time security monitoring"
        score_value: 5
    
    indicators:
      indicators:
        - "Frequency and consistency of AI security assessments"
        - "Scope and depth of security reviews"
        - "Automation level of security testing"
        - "Integration with development lifecycle"
        - "Policy enforcement mechanisms"
      
      definitions:
        level_1: "Security reviews happen sporadically without formal process"
        level_2: "Structured review process with defined criteria and documentation"
        level_3: "Automated tools perform regular security assessments for AI-specific risks"
        level_4: "Enhanced automation with comprehensive AI risk and vulnerability coverage"
        level_5: "Automated policy enforcement with real-time security monitoring"
      
      success_criteria:
        - "100% of AI systems undergo regular security reviews"
        - "Automated security testing integrated into CI/CD pipelines"
        - "Review findings tracked and remediated within defined SLAs"
        - "Security review processes continuously improved based on feedback"
    
    questions:
      - id: "sec_review_q1"
        text: "How frequently does your organization conduct AI security reviews?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No regular security reviews for AI systems"
          - "Ad-hoc reviews when issues arise"
          - "Scheduled reviews for major AI deployments"
          - "Regular reviews for all AI systems (monthly/quarterly)"
          - "Continuous automated security monitoring and review"
        help_text: "Consider reviews during development, pre-deployment, and post-deployment phases"
      
      - id: "sec_review_q2"
        text: "What is the scope and depth of your AI security reviews?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No structured review process"
          - "Basic checklist-based reviews"
          - "Comprehensive reviews covering AI-specific risks"
          - "In-depth reviews including model validation and threat modeling"
          - "Automated comprehensive reviews with real-time risk assessment"
        help_text: "Evaluate coverage of data security, model integrity, inference security, and operational risks"
      
      - id: "sec_review_q3"
        text: "How integrated are AI security reviews with your development lifecycle?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No integration with development processes"
          - "Reviews conducted separately from development"
          - "Reviews integrated at key development milestones"
          - "Reviews embedded throughout the development lifecycle"
          - "Automated reviews with continuous integration and deployment"
        help_text: "Consider integration with CI/CD, testing, and deployment processes"
      
      - id: "sec_review_q4"
        text: "Does your organization maintain a formal AI security review checklist or framework?"
        question_type: "boolean"
        weight: 0.7
        required: true
        slider_compatible: false
        help_text: "Indicate whether you have documented criteria, procedures, or frameworks that guide your AI security reviews"
      
      - id: "sec_review_q5"
        text: "Approximately how many AI security reviews has your organization conducted in the past 12 months?"
        question_type: "numeric"
        weight: 0.6
        required: false
        slider_compatible: false
        help_text: "Enter the total number of formal AI security reviews completed in the last year. Include both internal and external reviews."
      
      # Success Criteria Assessment Questions
      - id: "sec_review_sc_q1"
        text: "What percentage of your AI systems undergo regular security reviews?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "0-20% of AI systems reviewed regularly"
          - "21-40% of AI systems reviewed regularly"
          - "41-60% of AI systems reviewed regularly"
          - "61-80% of AI systems reviewed regularly"
          - "81-100% of AI systems reviewed regularly (meeting success criteria)"
        help_text: "Success criteria target is 100% coverage of all AI systems"
      
      - id: "sec_review_sc_q2"
        text: "How well is automated security testing integrated into your CI/CD pipelines for AI systems?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No automated security testing in CI/CD pipelines"
          - "Basic automated testing for some AI systems"
          - "Partial integration with manual oversight required"
          - "Well-integrated automated testing for most AI systems"
          - "Fully integrated automated testing across all AI CI/CD pipelines"
        help_text: "Evaluate the extent and effectiveness of automated security testing integration"
      
      - id: "sec_review_sc_q3"
        text: "How effectively are security review findings tracked and remediated within defined SLAs?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No systematic tracking or SLA management"
          - "Basic tracking with informal remediation timelines"
          - "Structured tracking with some SLA adherence"
          - "Good tracking with consistent SLA compliance"
          - "Comprehensive tracking with full SLA compliance and reporting"
        help_text: "Consider both the tracking mechanisms and adherence to service level agreements"
      
      - id: "sec_review_sc_q4"
        text: "How systematically does your organization improve security review processes based on feedback?"
        question_type: "single_choice"
        weight: 0.8
        required: true
        options:
          - "No systematic process improvement or feedback collection"
          - "Occasional improvements based on major issues"
          - "Regular feedback collection with some process updates"
          - "Systematic improvement process with regular updates"
          - "Continuous improvement with real-time feedback integration and optimization"
        help_text: "Evaluate the maturity of your process improvement and feedback integration mechanisms"

  shadow_ai_management:
    id: "shadow_ai_management"
    name: "Shadow AI Management"
    description: "Detection, prevention, and governance of unauthorized AI tool usage"
    pillar: "security_from_ai"
    weight: 1.1

    key_controls:
      - "AI asset discovery and inventory processes"
      - "Sanctioned AI tools catalog and approval workflow"
      - "Network monitoring for unauthorized AI service usage"
      - "Employee training on approved AI usage policies"
      - "Periodic audits for shadow AI detection"
    
    framework_alignment:
      - indicator: "Visibility into unauthorized AI tool usage"
        frameworks:
          nist_ai_rmf: ["GOVERN 1.4", "MEASURE 1.1"]
          iso_27001: ["A.12.6.2", "A.16.1.7"]
          nist_csf: ["ID.AM-1", "ID.AM-3"]
          iso_42001: ["8.2.1", "9.1", "8.6"]
          mitre_atlas: ["AML.T0035 - Develop Capabilities", "AML.T0052 - Phishing"]
          owasp_genai: ["LLM05:2025 Improper Output Handling - Discovery", "LLM10:2025 Unbounded Consumption - Visibility"]
      - indicator: "Detection capabilities for unapproved AI services"
        frameworks:
          nist_csf: ["DE.AE-1", "DE.CM-1"]
          iso_27001: ["A.12.4.1", "A.16.1.2"]
          soc2_security: ["CC6.1", "CC7.1"]
          iso_42001: ["8.6", "8.7", "9.1"]
          mitre_atlas: ["AML.T0035 - Develop Capabilities", "AML.T0052 - Phishing"]
          owasp_genai: ["LLM05:2025 Improper Output Handling - Discovery", "LLM10:2025 Unbounded Consumption - Visibility"]
      - indicator: "Prevention controls and access restrictions"
        frameworks:
          iso_27001: ["A.9.1.2", "A.13.1.1"]
          nist_csf: ["PR.AC-3", "PR.AC-4"]
          soc2_security: ["CC6.2", "CC6.3"]
          iso_42001: ["8.5.2", "7.1.4", "8.1"]
          mitre_atlas: ["AML.T0035 - Develop Capabilities", "AML.T0052 - Phishing"]
          owasp_genai: ["LLM05:2025 Improper Output Handling - Discovery", "LLM10:2025 Unbounded Consumption - Visibility"]
      - indicator: "Governance integration across data and AI domains"
        frameworks:
          nist_ai_rmf: ["GOVERN 2.1", "GOVERN 6.1"]
          iso_27001: ["A.5.1.1", "Clause 4.1"]
          cobit: ["DSS05.01", "DSS05.02"]
          iso_42001: ["4.1", "5.1", "8.1"]
          mitre_atlas: ["AML.T0035 - Develop Capabilities", "AML.T0052 - Phishing"]
          owasp_genai: ["LLM05:2025 Improper Output Handling - Discovery", "LLM10:2025 Unbounded Consumption - Visibility"]
      - indicator: "Monitoring and compliance reporting"
        frameworks:
          iso_27001: ["Clause 9.1", "A.18.2.1"]
          nist_csf: ["DE.CM-7", "RS.CO-2"]
          soc2_security: ["CC4.1", "CC4.2"]
          iso_42001: ["9.1", "9.3", "10.2"]
    
          mitre_atlas: ["AML.T0035 - Develop Capabilities", "AML.T0052 - Phishing"]
          owasp_genai: ["LLM05:2025 Improper Output Handling - Discovery", "LLM10:2025 Unbounded Consumption - Visibility"]
    levels:
      level_1:
        level: "level_1"
        name: "Uncontrolled Usage"
        description: "No awareness or control over unauthorized AI usage within the organization"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Detection Capability"
        description: "Basic detection mechanisms identify shadow AI usage patterns"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Prevention Controls"
        description: "Active prevention controls block unauthorized AI tool access"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Comprehensive Monitoring"
        description: "Comprehensive monitoring ensures all AI usage is governed and tracked"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Integrated Governance"
        description: "Fully integrated governance framework spanning AI, data, and security domains"
        score_value: 5
    
    indicators:
      indicators:
        - "Visibility into unauthorized AI tool usage"
        - "Detection capabilities for unapproved AI services"
        - "Prevention controls and access restrictions"
        - "Governance integration across data and AI domains"
        - "Monitoring and compliance reporting"
      
      definitions:
        level_1: "No awareness or control over unauthorized AI usage within the organization"
        level_2: "Basic detection mechanisms identify shadow AI usage patterns"
        level_3: "Active prevention controls block unauthorized AI tool access"
        level_4: "Comprehensive monitoring ensures all AI usage is governed and tracked"
        level_5: "Fully integrated governance framework spanning AI, data, and security domains"
      
      success_criteria:
        - "100% visibility into all AI tool usage across the organization"
        - "Automated detection and prevention of unauthorized AI services"
        - "Complete integration with data governance and security frameworks"
        - "Real-time monitoring and compliance reporting for all AI usage"
    
    questions:
      - id: "shadow_ai_q1"
        text: "How well does your organization detect unauthorized AI tool usage (shadow AI)?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No awareness or detection of shadow AI usage"
          - "Basic awareness but limited detection capabilities"
          - "Some detection through network monitoring or expense tracking"
          - "Comprehensive monitoring with dedicated detection tools"
          - "Real-time detection with automated alerts and governance integration"
        help_text: "Consider detection through network analysis, expense monitoring, endpoint detection, and user activity tracking"
      
      - id: "shadow_ai_q2"
        text: "What controls does your organization have to prevent unauthorized AI tool usage?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No prevention controls in place"
          - "Basic policy guidelines without enforcement"
          - "Network-level blocking of known unauthorized AI services"
          - "Comprehensive prevention with approved AI service catalogs"
          - "Integrated governance with automated policy enforcement"
        help_text: "Evaluate network controls, endpoint protection, approved service catalogs, and policy enforcement mechanisms"
      
      - id: "shadow_ai_q3"
        text: "How integrated is shadow AI management with your overall governance framework?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No integration with governance frameworks"
          - "Ad-hoc reporting on shadow AI incidents"
          - "Regular reporting integrated with IT governance"
          - "Integrated with data governance and security frameworks"
          - "Fully integrated across AI, data, and security governance with automated workflows"
        help_text: "Consider integration with data governance, security governance, IT risk management, and compliance reporting"
      
      - id: "shadow_ai_q4"
        text: "On a scale of 1-10, how confident is your organization in its ability to detect and prevent shadow AI usage?"
        question_type: "scale"
        weight: 0.8
        required: true
        slider_compatible: true
        options:
          - "1 - Not confident at all"
          - "2 - Very low confidence"
          - "3 - Low confidence"
          - "4 - Below average confidence"
          - "5 - Average confidence"
          - "6 - Above average confidence"
          - "7 - Good confidence"
          - "8 - High confidence"
          - "9 - Very high confidence"
          - "10 - Extremely confident"
        help_text: "Rate your overall confidence in your shadow AI detection and prevention capabilities"
      
      # Success Criteria Assessment Questions
      - id: "shadow_ai_sc_q1"
        text: "What percentage of AI tool usage across your organization do you have visibility into?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "0-20% visibility into AI tool usage"
          - "21-40% visibility into AI tool usage"
          - "41-60% visibility into AI tool usage"
          - "61-80% visibility into AI tool usage"
          - "81-100% visibility into AI tool usage (meeting success criteria)"
        help_text: "Success criteria target is 100% visibility into all AI tool usage"
      
      - id: "shadow_ai_sc_q2"
        text: "How effectively does your organization automatically detect and prevent unauthorized AI services?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No automated detection or prevention capabilities"
          - "Basic automated detection with manual prevention"
          - "Partial automation with some manual oversight"
          - "Well-automated detection and prevention for most scenarios"
          - "Fully automated detection and prevention across all AI services"
        help_text: "Evaluate both detection accuracy and prevention effectiveness"
      
      - id: "shadow_ai_sc_q3"
        text: "How completely is shadow AI management integrated with your data governance and security frameworks?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No integration with governance or security frameworks"
          - "Basic integration with some manual coordination"
          - "Partial integration with structured coordination"
          - "Well-integrated with most governance and security processes"
          - "Complete integration across all data governance and security frameworks"
        help_text: "Consider integration completeness across all relevant governance and security domains"
      
      - id: "shadow_ai_sc_q4"
        text: "How comprehensively does your organization provide real-time monitoring and compliance reporting for AI usage?"
        question_type: "single_choice"
        weight: 0.8
        required: true
        options:
          - "No real-time monitoring or compliance reporting"
          - "Basic monitoring with periodic manual reporting"
          - "Structured monitoring with regular automated reporting"
          - "Comprehensive monitoring with real-time dashboards"
          - "Full real-time monitoring with continuous compliance reporting and alerting"
        help_text: "Evaluate both the real-time nature of monitoring and comprehensiveness of compliance reporting"

  ai_agent_authorization:
    id: "ai_agent_authorization"
    name: "AI Agent Authorization & Access Control"
    description: "Authorization frameworks and access controls for autonomous AI agents and their tool/API usage"
    pillar: "security_from_ai"
    weight: 1.2

    key_controls:
      - "Agent identity and authentication frameworks"
      - "Authorization policies for agent tool/API access"
      - "Least privilege enforcement for autonomous agents"
      - "Dynamic access control based on agent behavior and risk"
      - "Permission boundaries and sandboxing for agents"
      - "Cross-system agent activity tracking and correlation"
      - "Agent session management and lifecycle controls"
      - "Audit logging for all agent actions and access attempts"
    
    framework_alignment:
      - indicator: "Agent authorization and access control frameworks"
        frameworks:
          nist_ai_rmf: ["GOVERN 1.5", "MANAGE 2.2", "MEASURE 2.7"]
          iso_27001: ["A.9.2.1", "A.9.4.1", "A.9.1.2"]
          nist_csf: ["PR.AC-4", "PR.AC-6", "PR.PT-3"]
          owasp_genai: ["LLM06:2025 Excessive Agency", "LLM09:2025 Misinformation"]
      - indicator: "Least privilege and permission boundaries"
        frameworks:
          nist_ai_rmf: ["MANAGE 2.2", "GOVERN 1.5"]
          iso_27001: ["A.9.2.3", "A.9.4.1"]
          nist_csf: ["PR.AC-4"]
          owasp_asvs: ["V4 - Access Control"]
      - indicator: "Agent activity monitoring and audit logging"
        frameworks:
          iso_27001: ["A.12.4.1", "A.12.4.3"]
          nist_csf: ["DE.CM-1", "DE.CM-6", "PR.PT-1"]
          soc2_security: ["CC6.1", "CC6.2"]
          nist_ai_rmf: ["MEASURE 4.2"]
      - indicator: "Dynamic risk-based access control"
        frameworks:
          nist_ai_rmf: ["MANAGE 2.2", "MEASURE 2.7"]
          nist_csf: ["PR.AC-6", "DE.CM-1"]
          iso_42001: ["8.6", "9.2"]
    
    levels:
      level_1:
        level: "level_1"
        name: "No Agent Controls"
        description: "No specific authorization or access controls for AI agents; agents operate with unrestricted access"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Basic Permissions"
        description: "Basic static permissions and manual access controls for AI agents"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Policy-Based Control"
        description: "Policy-based authorization with least privilege and permission boundaries for agents"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Dynamic Authorization"
        description: "Dynamic risk-based authorization with behavioral analysis and automated access adjustments"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Zero-Trust Agents"
        description: "Zero-trust authorization with continuous verification, context-aware policies, and real-time threat response"
        score_value: 5
    
    questions:
      - id: "agent_authz_q1"
        text: "How does your organization control what tools and APIs autonomous AI agents can access?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No specific controls for agent tool/API access"
          - "Manual approval process for agent capabilities"
          - "Static permission policies with predefined access levels"
          - "Dynamic authorization with behavior-based access controls"
          - "Zero-trust model with continuous verification and context-aware policies"
        help_text: "Consider tool access governance, API permissions, and capability restrictions for agents"
      
      - id: "agent_authz_q2"
        text: "How does your organization implement least privilege for AI agents?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No least privilege principles applied to agents"
          - "Ad-hoc access restrictions based on identified risks"
          - "Documented least privilege policies with manual enforcement"
          - "Automated least privilege with permission boundaries and sandboxing"
          - "Continuous least privilege optimization with ML-based access refinement"
        help_text: "Evaluate permission minimization, necessity-based access, and privilege escalation controls"
      
      - id: "agent_authz_q3"
        text: "How does your organization track and audit AI agent actions across systems?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No tracking or auditing of agent activities"
          - "Basic logging of agent actions in individual systems"
          - "Centralized logging with correlation across systems"
          - "Comprehensive audit trails with behavior analysis and anomaly detection"
          - "Real-time activity monitoring with automated threat response and forensic capabilities"
        help_text: "Consider logging, correlation, audit trails, and cross-system activity tracking"

    indicators:
      indicators:
        - "Agent authorization frameworks and policies"
        - "Least privilege enforcement and permission boundaries"
        - "Dynamic risk-based access control"
        - "Cross-system activity tracking and correlation"
        - "Audit logging and forensic capabilities"
      
      definitions:
        level_1: "No specific authorization or access controls for AI agents; agents operate with unrestricted access"
        level_2: "Basic static permissions and manual access controls for AI agents"
        level_3: "Policy-based authorization with least privilege and permission boundaries for agents"
        level_4: "Dynamic risk-based authorization with behavioral analysis and automated access adjustments"
        level_5: "Zero-trust authorization with continuous verification, context-aware policies, and real-time threat response"
      
      success_criteria:
        - "100% of AI agents subject to least privilege access controls"
        - "Complete audit trail for all agent actions across systems"
        - "Zero unauthorized agent access incidents"
        - "Dynamic authorization policies updated based on agent behavior and risk"
        - "Mean time to detect unauthorized agent access under 5 minutes"

  malicious_agent_detection:
    id: "malicious_agent_detection"
    name: "Malicious Agent Detection"
    description: "Detection and response capabilities for rogue, compromised, or malicious AI agents"
    pillar: "security_from_ai"
    weight: 1.3

    key_controls:
      - "Agent behavioral analysis and profiling"
      - "Anomaly detection for agent activities"
      - "Threat scoring and risk assessment for agents"
      - "Detection of coordinated multi-agent attacks"
      - "Agent impersonation and spoofing detection"
      - "Honeypots and deception techniques for malicious agents"
      - "Automated agent quarantine and containment"
      - "Incident response playbooks for malicious agents"
    
    framework_alignment:
      - indicator: "Malicious agent detection capabilities"
        frameworks:
          nist_ai_rmf: ["MEASURE 2.7", "MEASURE 4.2", "MANAGE 4.1"]
          iso_27001: ["A.12.4.1", "A.16.1.2", "A.16.1.4"]
          nist_csf: ["DE.CM-1", "DE.AE-2", "DE.AE-3"]
          owasp_genai: ["LLM06:2025 Excessive Agency", "LLM09:2025 Misinformation"]
      - indicator: "Agent behavioral analysis and threat scoring"
        frameworks:
          nist_ai_rmf: ["MEASURE 2.7", "MEASURE 4.2"]
          nist_csf: ["DE.CM-4", "DE.AE-2"]
          iso_42001: ["8.6", "9.2"]
      - indicator: "Coordinated attack detection"
        frameworks:
          nist_csf: ["DE.CM-1", "DE.AE-5"]
          iso_27001: ["A.16.1.2", "A.16.1.4"]
          mitre_atlas: ["AML.T0036 - Develop Adversarial Tools"]
      - indicator: "Automated response and containment"
        frameworks:
          nist_ai_rmf: ["MANAGE 4.1", "MANAGE 4.2"]
          nist_csf: ["RS.RP-1", "RS.MI-3"]
          iso_27001: ["A.16.1.5", "A.17.1.1"]
    
    levels:
      level_1:
        level: "level_1"
        name: "No Detection"
        description: "No capabilities to detect malicious or compromised AI agents"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Basic Monitoring"
        description: "Basic logging and manual review of agent activities"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Automated Detection"
        description: "Automated anomaly detection with behavioral analysis for agent threats"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Advanced Threat Detection"
        description: "Advanced detection with ML-based threat scoring and automated containment"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Predictive Defense"
        description: "Predictive threat detection with AI-powered analysis and autonomous response capabilities"
        score_value: 5
    
    questions:
      - id: "malicious_agent_q1"
        text: "What capabilities does your organization have to detect rogue or compromised AI agents?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No detection capabilities for malicious agents"
          - "Manual review of agent logs and activities"
          - "Automated anomaly detection with rule-based alerts"
          - "ML-based behavioral analysis with threat scoring"
          - "Predictive detection with AI-powered analysis and automated response"
        help_text: "Consider detection methods, behavioral analysis, and threat identification capabilities"
      
      - id: "malicious_agent_q2"
        text: "How does your organization detect coordinated attacks involving multiple AI agents?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No capability to detect multi-agent coordination"
          - "Manual correlation of agent activities across systems"
          - "Automated correlation with pattern-based detection"
          - "Advanced analytics with graph analysis and relationship mapping"
          - "AI-powered detection with real-time multi-agent threat modeling"
        help_text: "Evaluate cross-agent correlation, pattern detection, and coordinated attack identification"
      
      - id: "malicious_agent_q3"
        text: "What response capabilities does your organization have for detected malicious agents?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No automated response capabilities"
          - "Manual investigation and remediation"
          - "Automated alerting with manual containment"
          - "Automated containment and quarantine with guided remediation"
          - "Autonomous response with self-healing and adaptive defenses"
        help_text: "Consider containment, quarantine, remediation, and incident response procedures"

    indicators:
      indicators:
        - "Malicious agent detection accuracy and coverage"
        - "Behavioral analysis and threat scoring capabilities"
        - "Coordinated multi-agent attack detection"
        - "Response time and containment effectiveness"
        - "False positive rate and operational efficiency"
      
      definitions:
        level_1: "No capabilities to detect malicious or compromised AI agents"
        level_2: "Basic logging and manual review of agent activities"
        level_3: "Automated anomaly detection with behavioral analysis for agent threats"
        level_4: "Advanced detection with ML-based threat scoring and automated containment"
        level_5: "Predictive threat detection with AI-powered analysis and autonomous response capabilities"
      
      success_criteria:
        - "Malicious agent detection accuracy above 95%"
        - "Mean time to detect malicious agents under 10 minutes"
        - "Mean time to contain threats under 5 minutes"
        - "False positive rate below 5%"
        - "100% of detected threats automatically contained and investigated"

  agent_to_agent_security:
    id: "agent_to_agent_security"
    name: "Agent-to-Agent Security"
    description: "Security controls for communication, collaboration, and trust between autonomous AI agents"
    pillar: "security_from_ai"
    weight: 1.1

    key_controls:
      - "Secure communication protocols between agents"
      - "Agent identity verification and authentication"
      - "Trust establishment and validation frameworks"
      - "Protection against agent-based social engineering"
      - "Multi-agent system attack surface management"
      - "Agent collaboration security policies"
      - "Third-party agent security vetting and monitoring"
      - "Agent supply chain security controls"
    
    framework_alignment:
      - indicator: "Secure agent communication protocols"
        frameworks:
          nist_ai_rmf: ["GOVERN 1.2", "MANAGE 2.2"]
          iso_27001: ["A.13.1.1", "A.14.1.2", "A.14.1.3"]
          nist_csf: ["PR.DS-2", "PR.AC-5"]
      - indicator: "Agent trust and authentication frameworks"
        frameworks:
          nist_ai_rmf: ["GOVERN 1.5", "MAP 3.4"]
          iso_27001: ["A.9.2.1", "A.9.4.2", "A.15.1.2"]
          nist_csf: ["PR.AC-1", "PR.AC-7"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities"]
      - indicator: "Multi-agent attack surface management"
        frameworks:
          nist_ai_rmf: ["MAP 1.3", "MEASURE 2.7"]
          nist_csf: ["ID.AM-1", "ID.RA-1"]
          iso_27001: ["A.8.1.1", "A.18.1.3"]
      - indicator: "Agent supply chain security"
        frameworks:
          nist_ai_rmf: ["GOVERN 1.2", "MAP 3.4"]
          nist_ssdf: ["PO.3.1", "PO.3.2", "PS.1.1"]
          iso_27001: ["A.15.1.1", "A.15.1.2"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities"]
    
    levels:
      level_1:
        level: "level_1"
        name: "No Agent Security"
        description: "No security controls for agent-to-agent communication or collaboration"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Basic Controls"
        description: "Basic authentication and encryption for agent communications"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Secure Protocols"
        description: "Secure communication protocols with trust frameworks and verification"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Advanced Trust"
        description: "Advanced trust establishment with behavioral validation and supply chain security"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Zero-Trust Multi-Agent"
        description: "Zero-trust architecture with continuous verification and adaptive security for all agent interactions"
        score_value: 5
    
    questions:
      - id: "agent_to_agent_q1"
        text: "How does your organization secure communication between autonomous AI agents?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No specific security for agent-to-agent communication"
          - "Basic encryption for agent communications"
          - "Secure protocols with authentication and authorization"
          - "End-to-end encryption with mutual authentication and trust verification"
          - "Zero-trust communication with continuous verification and adaptive policies"
        help_text: "Consider encryption, authentication, protocol security, and trust establishment"
      
      - id: "agent_to_agent_q2"
        text: "How does your organization establish trust when agents collaborate or share information?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No trust framework for agent collaboration"
          - "Manual approval for agent-to-agent interactions"
          - "Policy-based trust with predefined collaboration rules"
          - "Dynamic trust scoring based on agent behavior and reputation"
          - "Continuous trust evaluation with blockchain-based verification and attestation"
        help_text: "Evaluate trust establishment, validation, reputation systems, and collaboration policies"
      
      - id: "agent_to_agent_q3"
        text: "How does your organization manage security risks from third-party AI agents?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No vetting or controls for third-party agents"
          - "Basic security questionnaires for third-party agents"
          - "Security assessment and approval process for external agents"
          - "Continuous monitoring and risk assessment of third-party agents"
          - "Comprehensive supply chain security with automated vetting and real-time monitoring"
        help_text: "Consider vendor assessment, agent vetting, monitoring, and supply chain security"

    indicators:
      indicators:
        - "Secure agent communication protocols"
        - "Trust establishment and verification frameworks"
        - "Agent identity and authentication strength"
        - "Third-party agent security vetting"
        - "Multi-agent attack surface visibility"
      
      definitions:
        level_1: "No security controls for agent-to-agent communication or collaboration"
        level_2: "Basic authentication and encryption for agent communications"
        level_3: "Secure communication protocols with trust frameworks and verification"
        level_4: "Advanced trust establishment with behavioral validation and supply chain security"
        level_5: "Zero-trust architecture with continuous verification and adaptive security for all agent interactions"
      
      success_criteria:
        - "100% of agent communications encrypted and authenticated"
        - "Trust verification for all agent-to-agent interactions"
        - "Security assessment completed for all third-party agents"
        - "Real-time monitoring of multi-agent collaboration patterns"
        - "Zero unauthorized agent-to-agent information sharing incidents"

  ai_security_tools:
    id: "ai_security_tools"
    name: "AI Security Tools"
    description: "Specialized tooling and capabilities for AI-specific security risks and vulnerabilities"
    pillar: "ai_for_security"
    weight: 1.0

    key_controls:
      - "AI-specific security tool evaluation and selection criteria"
      - "Integration of AI security tools into existing SIEM/SOAR"
      - "Model scanning and vulnerability assessment tools"
      - "Prompt injection detection and prevention tools"
      - "AI threat intelligence feed integration"
    
    framework_alignment:
      - indicator: "Coverage of AI-specific security vulnerabilities"
        frameworks:
          nist_ai_rmf: ["MEASURE 2.3", "MEASURE 2.5"]
          owasp_llm_top10: ["LLM01", "LLM02", "LLM03"]
          iso_27001: ["A.12.6.1", "A.14.2.1"]
          iso_42001: ["8.6", "8.7", "8.2.2"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Detection", "LLM06:2025 Excessive Agency - Monitoring"]
      - indicator: "Integration with existing security infrastructure"
        frameworks:
          nist_csf: ["PR.PT-1", "DE.CM-1"]
          iso_27001: ["A.13.1.1", "A.14.1.3"]
          soc2_security: ["CC6.1", "CC6.8"]
          iso_42001: ["8.1", "7.1.4", "8.3"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Detection", "LLM06:2025 Excessive Agency - Monitoring"]
      - indicator: "Specialized tooling for AI/ML workloads"
        frameworks:
          nist_ai_rmf: ["MANAGE 1.1", "MANAGE 1.2"]
          iso_27001: ["A.14.2.1", "A.14.2.8"]
          nist_csf: ["PR.IP-1", "DE.CM-4"]
          iso_42001: ["8.2", "8.3", "7.1.4"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Detection", "LLM06:2025 Excessive Agency - Monitoring"]
      - indicator: "Enterprise-wide deployment and adoption"
        frameworks:
          iso_27001: ["A.12.1.2", "A.14.1.1"]
          nist_csf: ["ID.GV-1", "PR.IP-3"]
          soc2_security: ["CC1.4", "CC5.1"]
          iso_42001: ["8.1", "5.1", "7.1"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Detection", "LLM06:2025 Excessive Agency - Monitoring"]
      - indicator: "Automation capabilities and threat response"
        frameworks:
          nist_csf: ["RS.RP-1", "RS.MI-1"]
          iso_27001: ["A.16.1.5", "A.16.1.6"]
          soc2_security: ["CC7.2", "CC7.4"]
          iso_42001: ["8.5.2", "8.6", "10.2"]
    
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Detection", "LLM06:2025 Excessive Agency - Monitoring"]
    levels:
      level_1:
        level: "level_1"
        name: "No Specialized Tools"
        description: "No tools to address AI Risks and Vulnerabilities"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Enhanced Existing Tools"
        description: "Incorporate AI Security features in existing tooling"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Specialized AI Tools"
        description: "Implement tools specific to AI Security risks and vulnerabilities in key domains (Data, Workload)"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Enterprise-wide Tools"
        description: "Tools across the enterprise addressing AI Security"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Automated Protection"
        description: "AI Security tooling implements automation to protect the enterprise"
        score_value: 5
    
    questions:
      - id: "ai_sec_tools_q1"
        text: "What AI-specific security tools does your organization currently use?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No specialized AI security tools in use"
          - "Basic tools with some AI security features"
          - "Dedicated AI security tools for specific domains (data, models, etc.)"
          - "Comprehensive AI security toolset across multiple domains"
          - "Enterprise-wide integrated AI security platform with automation"
        help_text: "Consider tools for model validation, data protection, inference security, and AI-specific vulnerability scanning"
      
      - id: "ai_sec_tools_q2"
        text: "How well are AI security tools integrated with your existing security infrastructure?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No integration with existing security tools"
          - "Basic integration with manual correlation"
          - "Moderate integration with some automated workflows"
          - "Well-integrated with centralized security management"
          - "Fully integrated with automated security orchestration and response"
        help_text: "Evaluate integration with SIEM, SOAR, vulnerability management, and incident response platforms"
      
      - id: "ai_sec_tools_q3"
        text: "What level of automation do your AI security tools provide?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "Manual tools requiring human intervention"
          - "Semi-automated tools with basic alerting"
          - "Automated scanning and reporting capabilities"
          - "Advanced automation with policy enforcement"
          - "Full automation with adaptive protection and self-healing capabilities"
        help_text: "Consider automation in threat detection, policy enforcement, remediation, and adaptive security measures"

    indicators:
      indicators:
        - "Coverage of AI-specific security vulnerabilities"
        - "Integration with existing security infrastructure"
        - "Specialized tooling for AI/ML workloads"
        - "Enterprise-wide deployment and adoption"
        - "Automation capabilities and threat response"
      
      definitions:
        level_1: "No specialized tools for AI security risks and vulnerabilities"
        level_2: "Basic AI security features added to existing security tools"
        level_3: "Dedicated AI security tools deployed for critical domains (data, workloads)"
        level_4: "Enterprise-wide AI security tool coverage across all domains"
        level_5: "Fully automated AI security tooling with proactive threat protection"
      
      success_criteria:
        - "100% coverage of AI workloads and data with specialized security tools"
        - "Integration with existing security infrastructure and workflows"
        - "Automated threat detection and response capabilities"
        - "Regular tool effectiveness assessments and improvements"

  development_integration:
    id: "development_integration"
    name: "Development Integration"
    description: "Integration of AI security practices into software development lifecycles"
    pillar: "security_for_ai"
    weight: 1.2

    key_controls:
      - "Secure ML development guidelines and checklists"
      - "Security requirements in AI project inception"
      - "Secure coding standards for ML pipelines"
      - "Dependency scanning for ML libraries and frameworks"
      - "Security sign-off required for model deployment"
    
    framework_alignment:
      - indicator: "AI security practices in software development lifecycle"
        frameworks:
          nist_ssdf: ["PO.1.1", "PO.1.3", "PS.1.1"]
          iso_27001: ["A.14.1.1", "A.14.2.1"]
          nist_csf: ["PR.IP-2", "DE.CM-4"]
          iso_42001: ["8.2", "8.3", "8.4"]
          mitre_atlas: ["AML.T0010 - ML Supply Chain Compromise", "AML.T0042 - Verify Attack"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities", "LLM05:2025 Improper Output Handling"]
      - indicator: "CI/CD pipeline security integration"
        frameworks:
          nist_ssdf: ["PS.2.1", "PS.3.1", "PW.4.1"]
          iso_27001: ["A.14.2.2", "A.14.2.6"]
          owasp_samm: ["ST1.1", "ST2.2"]
          iso_42001: ["8.3", "8.4", "8.6"]
          mitre_atlas: ["AML.T0010 - ML Supply Chain Compromise", "AML.T0042 - Verify Attack"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities", "LLM05:2025 Improper Output Handling"]
      - indicator: "Developer training and awareness programs"
        frameworks:
          nist_ssdf: ["PO.2.1", "PO.2.2"]
          iso_27001: ["A.7.2.2", "A.7.2.3"]
          soc2_security: ["CC1.4", "CC1.5"]
          iso_42001: ["7.2", "7.3", "7.4"]
          mitre_atlas: ["AML.T0010 - ML Supply Chain Compromise", "AML.T0042 - Verify Attack"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities", "LLM05:2025 Improper Output Handling"]
      - indicator: "Security testing automation"
        frameworks:
          nist_ssdf: ["PW.7.1", "PW.7.2"]
          iso_27001: ["A.14.2.3", "A.14.2.8"]
          owasp_samm: ["ST2.1", "ST3.2"]
          iso_42001: ["8.2.2", "8.6", "8.7"]
          mitre_atlas: ["AML.T0010 - ML Supply Chain Compromise", "AML.T0042 - Verify Attack"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities", "LLM05:2025 Improper Output Handling"]
      - indicator: "Application-level AI security controls"
        frameworks:
          nist_ai_rmf: ["MANAGE 2.1", "MANAGE 2.2"]
          owasp_llm_top10: ["LLM04", "LLM10"]
          iso_27001: ["A.14.1.2", "A.14.1.3"]
          iso_42001: ["8.2.2", "8.5.2", "8.6"]
    
          mitre_atlas: ["AML.T0010 - ML Supply Chain Compromise", "AML.T0042 - Verify Attack"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities", "LLM05:2025 Improper Output Handling"]
    levels:
      level_1:
        level: "level_1"
        name: "No Integration"
        description: "No AI security incorporated into coding and app development"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Best Practices"
        description: "App development incorporates AI Security best practices"
        score_value: 2
      level_3:
        level: "level_3"
        name: "CI/CD Integration"
        description: "AI Security tooling incorporated into CI/CD for app development"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Integrated Tooling"
        description: "AI Security tooling integrated with CI/CD tooling (e.g. detected weaknesses during scans used to create policies on AI Security tools)"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Security Layer"
        description: "All AI applications have an AI Security layer as part of its security"
        score_value: 5
    
    questions:
      - id: "dev_integration_q1"
        text: "How well are AI security practices integrated into your software development lifecycle?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No AI security practices in development processes"
          - "Basic AI security guidelines for developers"
          - "AI security checkpoints at key development milestones"
          - "AI security fully integrated into CI/CD pipelines"
          - "Automated AI security layer in all applications with continuous monitoring"
        help_text: "Consider integration in code review, testing, deployment, and runtime monitoring phases"
      
      - id: "dev_integration_q2"
        text: "What AI security tools are integrated into your CI/CD pipelines?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No AI security tools in CI/CD pipelines"
          - "Basic static analysis with some AI security checks"
          - "Dedicated AI security scanning tools in build processes"
          - "Comprehensive AI security testing throughout CI/CD"
          - "Automated AI security validation with policy enforcement and feedback loops"
        help_text: "Evaluate tools for model validation, dependency scanning, configuration checks, and runtime security testing"
      
      - id: "dev_integration_q3"
        text: "How do development teams receive feedback and guidance on AI security issues?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No structured feedback on AI security issues"
          - "Manual reporting of AI security findings"
          - "Automated alerts with basic remediation guidance"
          - "Integrated feedback with detailed remediation recommendations"
          - "Real-time guidance with automated fix suggestions and continuous learning"
        help_text: "Consider feedback mechanisms, training integration, and knowledge sharing processes"
      
      # Success Criteria Assessment Questions
      - id: "dev_integration_sc_q1"
        text: "What percentage of your AI development projects follow security-by-design principles?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "0-20% of AI development projects follow security-by-design"
          - "21-40% of AI development projects follow security-by-design"
          - "41-60% of AI development projects follow security-by-design"
          - "61-80% of AI development projects follow security-by-design"
          - "81-100% of AI development projects follow security-by-design (meeting success criteria)"
        help_text: "Success criteria target is 100% adoption of security-by-design principles"
      
      - id: "dev_integration_sc_q2"
        text: "What percentage of your AI CI/CD pipelines include automated security testing?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "0-20% of CI/CD pipelines have automated security testing"
          - "21-40% of CI/CD pipelines have automated security testing"
          - "41-60% of CI/CD pipelines have automated security testing"
          - "61-80% of CI/CD pipelines have automated security testing"
          - "81-100% of CI/CD pipelines have automated security testing (meeting success criteria)"
        help_text: "Success criteria target is automated security testing in all CI/CD pipelines"
      
      - id: "dev_integration_sc_q3"
        text: "What is your current developer security training completion rate?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "0-20% completion rate"
          - "21-40% completion rate"
          - "41-60% completion rate"
          - "61-80% completion rate"
          - "81-95% completion rate"
          - "95-100% completion rate (meeting success criteria)"
        help_text: "Success criteria target is above 95% completion rate for developer security training"
      
      - id: "dev_integration_sc_q4"
        text: "How many critical security vulnerabilities are currently in your production AI applications?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "More than 10 critical vulnerabilities"
          - "6-10 critical vulnerabilities"
          - "3-5 critical vulnerabilities"
          - "1-2 critical vulnerabilities"
          - "Zero critical vulnerabilities (meeting success criteria)"
        help_text: "Success criteria target is zero critical security vulnerabilities in production"

    indicators:
      indicators:
        - "AI security practices in software development lifecycle"
        - "CI/CD pipeline security integration"
        - "Developer training and awareness programs"
        - "Security testing automation"
        - "Application-level AI security controls"
      
      definitions:
        level_1: "No AI security considerations in development processes"
        level_2: "Development teams follow AI security best practices and guidelines"
        level_3: "AI security tools integrated into CI/CD pipelines for automated testing"
        level_4: "Advanced integration where security findings drive policy creation and enforcement"
        level_5: "Every AI application includes integrated security layers by design"
      
      success_criteria:
        - "100% of AI development projects follow security-by-design principles"
        - "Automated security testing in all CI/CD pipelines"
        - "Developer security training completion rates above 95%"
        - "Zero critical security vulnerabilities in production AI applications"

  asset_management:
    id: "asset_management"
    name: "Asset Management"
    description: "Inventory, tracking, and lifecycle management of AI models and data assets"
    pillar: "security_for_ai"
    weight: 1.1

    key_controls:
      - "Comprehensive AI/ML asset inventory and classification"
      - "Model versioning and lineage tracking"
      - "Data provenance and source documentation"
      - "Third-party AI component inventory"
      - "Asset lifecycle management and decommissioning procedures"
    
    framework_alignment:
      - indicator: "Inventory completeness for AI models and training data"
        frameworks:
          nist_ai_rmf: ["GOVERN 1.4", "MAP 1.3"]
          iso_27001: ["A.8.1.1", "A.8.1.2"]
          nist_csf: ["ID.AM-1", "ID.AM-2"]
          iso_42001: ["8.2.1", "7.5", "8.1"]
          mitre_atlas: ["AML.T0047 - ML Supply Chain Compromise", "AML.T0035 - Develop Capabilities"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities - Inventory", "LLM10:2025 Unbounded Consumption - Asset Tracking"]
      - indicator: "Lineage tracking and dependency mapping"
        frameworks:
          nist_ai_rmf: ["MAP 1.4", "MANAGE 1.3"]
          iso_27001: ["A.8.2.1", "A.8.2.3"]
          dmbok: ["DM2.1", "DM11.2"]
          iso_42001: ["8.2.1", "8.2.2", "7.5"]
          mitre_atlas: ["AML.T0047 - ML Supply Chain Compromise", "AML.T0035 - Develop Capabilities"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities - Inventory", "LLM10:2025 Unbounded Consumption - Asset Tracking"]
      - indicator: "Performance monitoring and drift detection"
        frameworks:
          nist_ai_rmf: ["MEASURE 2.1", "MEASURE 2.2"]
          iso_27001: ["A.12.1.4", "Clause 9.1"]
          mlops_principles: ["Monitor.1", "Monitor.2"]
          iso_42001: ["8.6", "9.1", "9.2"]
          mitre_atlas: ["AML.T0047 - ML Supply Chain Compromise", "AML.T0035 - Develop Capabilities"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities - Inventory", "LLM10:2025 Unbounded Consumption - Asset Tracking"]
      - indicator: "Version control and change management"
        frameworks:
          iso_27001: ["A.12.1.2", "A.14.2.2"]
          nist_ssdf: ["PO.1.2", "PS.3.2"]
          cobit: ["BAI06.01", "BAI06.02"]
          iso_42001: ["8.4", "8.5.1", "7.5"]
          mitre_atlas: ["AML.T0047 - ML Supply Chain Compromise", "AML.T0035 - Develop Capabilities"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities - Inventory", "LLM10:2025 Unbounded Consumption - Asset Tracking"]
      - indicator: "Continuous monitoring capabilities"
        frameworks:
          nist_csf: ["DE.CM-1", "DE.CM-7"]
          iso_27001: ["A.12.4.1", "A.16.1.2"]
          soc2_security: ["CC7.1", "CC7.2"]
          iso_42001: ["8.6", "9.1", "9.3"]
    
          mitre_atlas: ["AML.T0047 - ML Supply Chain Compromise", "AML.T0035 - Develop Capabilities"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities - Inventory", "LLM10:2025 Unbounded Consumption - Asset Tracking"]
    levels:
      level_1:
        level: "level_1"
        name: "No Inventory"
        description: "No AI model and data inventory"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Basic Inventory"
        description: "AI models and data inventoried"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Lineage Tracking"
        description: "AI model lineage established. Data lineage established"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Performance Tracking"
        description: "AI model performance tracking across lineage"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Continuous Monitoring"
        description: "Continuous monitoring of model performance"
        score_value: 5
    
    questions:
      - id: "asset_mgmt_q1"
        text: "How comprehensive is your organization's AI model and data asset inventory?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No centralized inventory of AI models or data assets"
          - "Basic inventory with manual tracking of major AI assets"
          - "Structured inventory with metadata and classification"
          - "Comprehensive automated inventory with lineage tracking"
          - "Real-time asset discovery and management with full lifecycle tracking"
        help_text: "Consider coverage of models, datasets, APIs, training data, and third-party AI services"
      
      - id: "asset_mgmt_q2"
        text: "How well does your organization track AI model lineage and dependencies?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No tracking of model lineage or dependencies"
          - "Basic documentation of model origins and training data"
          - "Structured lineage tracking with dependency mapping"
          - "Automated lineage tracking with version control and impact analysis"
          - "Comprehensive lineage management with real-time dependency monitoring"
        help_text: "Evaluate tracking of training data, model versions, dependencies, and downstream applications"
      
      - id: "asset_mgmt_q3"
        text: "How does your organization monitor AI model performance and drift over time?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No systematic monitoring of model performance"
          - "Periodic manual checks of model accuracy"
          - "Automated performance monitoring with basic alerting"
          - "Comprehensive drift detection with automated retraining triggers"
          - "Continuous monitoring with adaptive models and predictive maintenance"
        help_text: "Consider monitoring of accuracy, bias, performance degradation, and data drift detection"

    indicators:
      indicators:
        - "Inventory completeness for AI models and training data"
        - "Lineage tracking and dependency mapping"
        - "Performance monitoring and drift detection"
        - "Version control and change management"
        - "Continuous monitoring capabilities"
      
      definitions:
        level_1: "No systematic tracking of AI models or associated data assets"
        level_2: "Basic inventory of AI models and data with cataloging systems"
        level_3: "Comprehensive lineage tracking for both models and data dependencies"
        level_4: "Active performance monitoring across the entire AI asset lifecycle"
        level_5: "Continuous real-time monitoring with automated alerting and response"
      
      success_criteria:
        - "100% of AI models and datasets are inventoried and tracked"
        - "Complete lineage documentation for all AI assets"
        - "Automated drift detection and alerting systems"
        - "Regular performance reviews and model updates"

  team_structure:
    id: "team_structure"
    name: "Team Structure"
    description: "Organizational structure and expertise for AI security management"
    pillar: "security_for_ai"
    weight: 0.9

    key_controls:
      - "Defined AI security roles and responsibilities"
      - "AI security training requirements for development teams"
      - "Cross-functional AI security working groups"
      - "AI security awareness programs organization-wide"
      - "Career paths and skill development for AI security"
    
    framework_alignment:
      - indicator: "Dedicated AI security personnel and expertise"
        frameworks:
          nist_ai_rmf: ["GOVERN 1.6", "GOVERN 2.2"]
          iso_27001: ["A.6.1.1", "A.7.1.1"]
          nist_csf: ["ID.GV-2", "PR.AT-1"]
          iso_42001: ["5.3", "7.2", "7.3"]
          mitre_atlas: ["AML.T0052 - Phishing", "AML.T0050 - Command and Scripting Interpreter"]
          owasp_genai: ["LLM07:2025 System Prompt Leakage - Training", "LLM06:2025 Excessive Agency - Skills"]
      - indicator: "Cross-functional collaboration and integration"
        frameworks:
          iso_27001: ["A.6.1.2", "A.6.1.3"]
          nist_csf: ["ID.GV-1", "ID.GV-3"]
          soc2_security: ["CC1.1", "CC1.2"]
          iso_42001: ["5.3", "7.4", "8.1"]
          mitre_atlas: ["AML.T0052 - Phishing", "AML.T0050 - Command and Scripting Interpreter"]
          owasp_genai: ["LLM07:2025 System Prompt Leakage - Training", "LLM06:2025 Excessive Agency - Skills"]
      - indicator: "Clear roles, responsibilities, and deliverables"
        frameworks:
          iso_27001: ["A.6.1.1", "A.7.1.2"]
          nist_csf: ["ID.GV-2", "PR.AT-2"]
          cobit: ["APO01.01", "APO01.02"]
          iso_42001: ["5.3", "7.1", "8.1"]
          mitre_atlas: ["AML.T0052 - Phishing", "AML.T0050 - Command and Scripting Interpreter"]
          owasp_genai: ["LLM07:2025 System Prompt Leakage - Training", "LLM06:2025 Excessive Agency - Skills"]
      - indicator: "Training and skill development programs"
        frameworks:
          iso_27001: ["A.7.2.1", "A.7.2.2"]
          nist_csf: ["PR.AT-1", "PR.AT-2"]
          soc2_security: ["CC1.4", "CC1.5"]
          iso_42001: ["7.2", "7.3", "7.4"]
          mitre_atlas: ["AML.T0052 - Phishing", "AML.T0050 - Command and Scripting Interpreter"]
          owasp_genai: ["LLM07:2025 System Prompt Leakage - Training", "LLM06:2025 Excessive Agency - Skills"]
      - indicator: "Organizational AI security culture"
        frameworks:
          nist_ai_rmf: ["GOVERN 6.1", "GOVERN 6.2"]
          iso_27001: ["A.7.2.1", "Clause 7.2"]
          nist_csf: ["ID.GV-4", "PR.AT-3"]
          iso_42001: ["5.1", "7.2", "7.4"]
    
          mitre_atlas: ["AML.T0052 - Phishing", "AML.T0050 - Command and Scripting Interpreter"]
          owasp_genai: ["LLM07:2025 System Prompt Leakage - Training", "LLM06:2025 Excessive Agency - Skills"]
    levels:
      level_1:
        level: "level_1"
        name: "No Dedicated Team"
        description: "No dedicated AI Security team"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Basic Team"
        description: "AI Security Team created to address evolving AI Security needs"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Effective Team"
        description: "AI Security team delivers clear deliverables for other security and IT teams"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Integrated Security"
        description: "AI Security incorporated across all security teams"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Organization-wide"
        description: "AI Security incorporated across all IT and Business teams"
        score_value: 5
    
    questions:
      - id: "team_structure_q1"
        text: "What dedicated AI security expertise does your organization have?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No dedicated AI security roles or expertise"
          - "AI security handled by general security team members"
          - "Dedicated AI security specialist(s) within security team"
          - "Established AI security team with specialized roles"
          - "AI security expertise embedded across all relevant teams organization-wide"
        help_text: "Consider dedicated roles, training programs, and distribution of AI security knowledge"
      
      - id: "team_structure_q2"
        text: "How well does your AI security team collaborate with other organizational units?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No structured collaboration between teams"
          - "Ad-hoc collaboration when issues arise"
          - "Regular coordination meetings and shared responsibilities"
          - "Integrated workflows with clear handoffs and accountability"
          - "Seamless collaboration with AI security embedded in all relevant processes"
        help_text: "Evaluate collaboration with IT, development, data science, compliance, and business teams"
      
      - id: "team_structure_q3"
        text: "How does your organization ensure AI security knowledge and skills are maintained?"
        question_type: "single_choice"
        weight: 0.8
        required: true
        options:
          - "No formal AI security training or knowledge management"
          - "Basic training materials and occasional workshops"
          - "Regular training programs and knowledge sharing sessions"
          - "Comprehensive skill development with certification and career paths"
          - "Continuous learning with adaptive training and knowledge management systems"
        help_text: "Consider training programs, certifications, knowledge retention, and skill development initiatives"

    indicators:
      indicators:
        - "Dedicated AI security personnel and expertise"
        - "Cross-functional collaboration and integration"
        - "Clear roles, responsibilities, and deliverables"
        - "Training and skill development programs"
        - "Organizational AI security culture"
      
      definitions:
        level_1: "No dedicated AI security team or specialized expertise"
        level_2: "Basic AI security team established to address emerging needs"
        level_3: "Mature AI security team providing clear deliverables to other teams"
        level_4: "AI security expertise integrated across all security functions"
        level_5: "AI security knowledge and practices embedded throughout IT and business teams"
      
      success_criteria:
        - "Dedicated AI security team with defined roles and responsibilities"
        - "Regular training and skill development programs"
        - "Cross-functional collaboration metrics above 90%"
        - "AI security expertise distributed across all relevant teams"

  training_data_privacy:
    id: "training_data_privacy"
    name: "Training Data Privacy"
    description: "Privacy-preserving techniques and controls for AI training data protection"
    pillar: "security_for_ai"
    weight: 1.3

    key_controls:
      - "Privacy impact assessments for training data collection and use"
      - "Privacy-enhancing technologies (PETs) implementation (differential privacy, federated learning, homomorphic encryption)"
      - "Data minimization and purpose limitation for training datasets"
      - "Anonymization and pseudonymization of training data"
      - "Synthetic data generation for privacy-preserving training"
      - "Consent management and data subject rights enforcement"
      - "Privacy-preserving model training techniques"
      - "Regular privacy audits and compliance validation"
    
    framework_alignment:
      - indicator: "Privacy-enhancing technologies for training data"
        frameworks:
          nist_ai_rmf: ["GOVERN 1.4", "MAP 1.6", "MEASURE 2.8"]
          iso_27001: ["A.18.1.4", "A.8.2.1", "A.8.3.1"]
          iso_42001: ["6.2.1", "7.3", "8.5"]
          nist_csf: ["PR.DS-3", "PR.IP-2"]
      - indicator: "Data minimization and purpose limitation"
        frameworks:
          iso_27701: ["6.3.2.2", "6.3.3.2"]
          iso_42001: ["6.2.1", "7.3"]
          nist_ai_rmf: ["MAP 1.6", "GOVERN 1.4"]
      - indicator: "Consent management and data subject rights"
        frameworks:
          iso_27701: ["6.4.1", "6.5.1"]
          iso_27001: ["A.18.1.4"]
      - indicator: "Privacy-preserving model training"
        frameworks:
          nist_ai_rmf: ["MAP 1.6", "MEASURE 2.8"]
          iso_42001: ["7.3", "8.5"]
    
    levels:
      level_1:
        level: "level_1"
        name: "No Privacy Controls"
        description: "No privacy-specific controls for training data; minimal awareness of privacy risks"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Basic Anonymization"
        description: "Basic data anonymization and minimal privacy controls for training datasets"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Privacy by Design"
        description: "Privacy-by-design principles with PETs implementation (differential privacy, federated learning)"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Advanced PETs"
        description: "Advanced privacy-enhancing technologies with synthetic data and homomorphic encryption"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Privacy-First AI"
        description: "Comprehensive privacy-first AI development with zero-knowledge proofs and continuous privacy assurance"
        score_value: 5
    
    questions:
      - id: "training_data_privacy_q1"
        text: "What privacy-enhancing technologies does your organization use for training data?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No specific privacy-enhancing technologies implemented"
          - "Basic anonymization and data masking techniques"
          - "Differential privacy or federated learning for selected models"
          - "Multiple PETs including synthetic data generation and secure multi-party computation"
          - "Comprehensive PETs suite with homomorphic encryption and zero-knowledge proofs"
        help_text: "Consider differential privacy, federated learning, homomorphic encryption, synthetic data, and secure computation"
      
      - id: "training_data_privacy_q2"
        text: "How does your organization ensure data minimization for AI training?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No data minimization practices for training datasets"
          - "Ad-hoc data reduction based on storage constraints"
          - "Documented data minimization policies with manual enforcement"
          - "Automated data minimization with purpose limitation controls"
          - "Privacy-by-design with automated minimization and continuous optimization"
        help_text: "Evaluate collection limitations, purpose specification, and retention controls"
      
      - id: "training_data_privacy_q3"
        text: "How does your organization handle consent and data subject rights for training data?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No consent management or data subject rights processes"
          - "Basic consent collection with manual tracking"
          - "Consent management system with data subject request handling"
          - "Automated consent enforcement with model retraining for data deletion"
          - "Real-time consent and rights management integrated throughout AI lifecycle"
        help_text: "Consider consent collection, tracking, withdrawal, right to deletion, and model unlearning"

    indicators:
      indicators:
        - "Privacy-enhancing technologies implementation"
        - "Data minimization and purpose limitation"
        - "Anonymization and synthetic data usage"
        - "Consent management and data subject rights"
        - "Privacy-preserving model training techniques"
      
      definitions:
        level_1: "No privacy-specific controls for training data; minimal awareness of privacy risks"
        level_2: "Basic data anonymization and minimal privacy controls for training datasets"
        level_3: "Privacy-by-design principles with PETs implementation (differential privacy, federated learning)"
        level_4: "Advanced privacy-enhancing technologies with synthetic data and homomorphic encryption"
        level_5: "Comprehensive privacy-first AI development with zero-knowledge proofs and continuous privacy assurance"
      
      success_criteria:
        - "Privacy-enhancing technologies deployed for 100% of sensitive training data"
        - "Data minimization enforced with automated purpose limitation controls"
        - "Consent and data subject rights integrated into model training pipelines"
        - "Privacy impact assessments completed for all AI systems processing personal data"
        - "Compliance with GDPR, CCPA, and relevant privacy regulations verified"

  training_data_security:
    id: "training_data_security"
    name: "Training Data Security"
    description: "Security controls and protection mechanisms for AI training data throughout its lifecycle"
    pillar: "security_for_ai"
    weight: 1.2

    key_controls:
      - "Training data classification and labeling"
      - "Access controls and least privilege for training datasets"
      - "Encryption at rest and in transit for training data"
      - "Data lineage and provenance tracking"
      - "Training data integrity verification and validation"
      - "Secure data storage and backup procedures"
      - "Data exfiltration prevention for training datasets"
      - "Audit logging for training data access and modifications"
    
    framework_alignment:
      - indicator: "Training data classification and access controls"
        frameworks:
          nist_ai_rmf: ["GOVERN 1.2", "MAP 5.1"]
          iso_27001: ["A.8.2.1", "A.9.4.1", "A.9.2.1"]
          iso_42001: ["7.3", "8.5"]
          nist_csf: ["PR.DS-5", "PR.AC-4"]
      - indicator: "Data encryption and secure storage"
        frameworks:
          iso_27001: ["A.10.1.1", "A.10.1.2"]
          nist_csf: ["PR.DS-1", "PR.DS-2"]
          soc2_security: ["CC6.1", "CC6.7"]
      - indicator: "Data lineage and provenance tracking"
        frameworks:
          nist_ai_rmf: ["MAP 3.4", "MEASURE 3.1"]
          iso_42001: ["7.3", "8.5"]
      - indicator: "Training data integrity verification"
        frameworks:
          nist_ai_rmf: ["MEASURE 2.3", "MEASURE 3.1"]
          iso_27001: ["A.12.2.1", "A.14.1.2"]
          iso_42001: ["8.5"]
    
    levels:
      level_1:
        level: "level_1"
        name: "Minimal Protection"
        description: "Minimal security controls for training data; no classification or access restrictions"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Basic Controls"
        description: "Basic access controls and encryption for training data storage"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Comprehensive Security"
        description: "Comprehensive security controls with classification, encryption, and data lineage tracking"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Advanced Protection"
        description: "Advanced protection with integrity verification, DLP, and automated security enforcement"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Zero-Trust Data Security"
        description: "Zero-trust architecture with continuous verification, automated threat response, and immutable audit trails"
        score_value: 5
    
    questions:
      - id: "training_data_security_q1"
        text: "How does your organization classify and protect training data?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No classification or specific protection for training data"
          - "Basic classification with standard file system permissions"
          - "Formal classification scheme with role-based access controls"
          - "Advanced classification with automated access enforcement and encryption"
          - "Dynamic classification with zero-trust controls and continuous verification"
        help_text: "Consider data classification, labeling, access controls, and protection mechanisms"
      
      - id: "training_data_security_q2"
        text: "How does your organization track training data lineage and provenance?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No tracking of data sources or lineage for training datasets"
          - "Manual documentation of primary data sources"
          - "Automated lineage tracking for data collection and preprocessing"
          - "Comprehensive provenance tracking throughout the ML pipeline"
          - "Real-time lineage monitoring with cryptographic verification and blockchain"
        help_text: "Evaluate tracking of data sources, transformations, versioning, and chain of custody"
      
      - id: "training_data_security_q3"
        text: "What controls does your organization have for training data integrity?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No integrity verification for training datasets"
          - "Basic checksums or hash verification for stored datasets"
          - "Automated integrity checks during data ingestion and training"
          - "Continuous integrity monitoring with tamper detection"
          - "Cryptographic integrity verification with immutable audit trails"
        help_text: "Consider data validation, poisoning detection, tamper protection, and integrity assurance"

    indicators:
      indicators:
        - "Training data classification and labeling"
        - "Access controls and encryption"
        - "Data lineage and provenance tracking"
        - "Integrity verification and validation"
        - "Exfiltration prevention and monitoring"
      
      definitions:
        level_1: "Minimal security controls for training data; no classification or access restrictions"
        level_2: "Basic access controls and encryption for training data storage"
        level_3: "Comprehensive security controls with classification, encryption, and data lineage tracking"
        level_4: "Advanced protection with integrity verification, DLP, and automated security enforcement"
        level_5: "Zero-trust architecture with continuous verification, automated threat response, and immutable audit trails"
      
      success_criteria:
        - "100% of training datasets classified and labeled according to sensitivity"
        - "Encryption at rest and in transit for all sensitive training data"
        - "Complete data lineage tracking from source to model deployment"
        - "Automated integrity verification with 99.9% detection rate for tampering"
        - "Zero unauthorized access incidents to training data"

  data_poisoning_protection:
    id: "data_poisoning_protection"
    name: "Data Poisoning Protection"
    description: "Detection and prevention of data poisoning attacks against AI training datasets"
    pillar: "security_for_ai"
    weight: 1.2

    key_controls:
      - "Training data validation and sanitization"
      - "Anomaly detection for poisoned data samples"
      - "Data source verification and trust scoring"
      - "Statistical analysis for distribution shifts"
      - "Poisoning attack simulation and testing"
      - "Data provenance and chain of custody verification"
      - "Automated outlier detection and filtering"
      - "Regular training data audits and reviews"
    
    framework_alignment:
      - indicator: "Data poisoning detection and prevention"
        frameworks:
          nist_ai_rmf: ["MAP 3.4", "MEASURE 2.3", "MANAGE 2.3"]
          iso_42001: ["8.5", "8.7"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities", "LLM04:2025 Data and Model Poisoning"]
          mitre_atlas: ["AML.T0018 - Backdoor ML Model", "AML.T0020 - Poison Training Data"]
      - indicator: "Data source verification and trust"
        frameworks:
          nist_ai_rmf: ["MAP 3.4", "GOVERN 1.2"]
          iso_27001: ["A.15.1.1", "A.15.1.2"]
          nist_ssdf: ["PO.3.1", "PO.3.2"]
      - indicator: "Anomaly and outlier detection"
        frameworks:
          nist_ai_rmf: ["MEASURE 2.3", "MEASURE 2.7"]
          iso_42001: ["8.5", "8.7"]
      - indicator: "Poisoning attack testing"
        frameworks:
          nist_ai_rmf: ["MEASURE 2.11", "MANAGE 4.1"]
          mitre_atlas: ["AML.T0018 - Backdoor ML Model", "AML.T0020 - Poison Training Data"]
    
    levels:
      level_1:
        level: "level_1"
        name: "No Protection"
        description: "No awareness or protection against data poisoning attacks"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Basic Validation"
        description: "Basic data validation and manual review of training datasets"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Automated Detection"
        description: "Automated anomaly detection with statistical analysis for poisoning attempts"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Advanced Prevention"
        description: "Advanced prevention with provenance tracking, automated filtering, and attack simulation"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Adaptive Defense"
        description: "Adaptive defenses with ML-based detection, continuous monitoring, and self-healing datasets"
        score_value: 5
    
    questions:
      - id: "data_poisoning_q1"
        text: "What controls does your organization have to detect data poisoning in training datasets?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No specific data poisoning detection capabilities"
          - "Manual review and basic statistical analysis of training data"
          - "Automated anomaly detection with threshold-based alerts"
          - "Advanced detection with ML-based outlier identification and filtering"
          - "Adaptive detection with continuous learning and automated remediation"
        help_text: "Consider validation, anomaly detection, distribution analysis, and automated filtering"
      
      - id: "data_poisoning_q2"
        text: "How does your organization verify the trustworthiness of training data sources?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No verification of data source trustworthiness"
          - "Manual assessment of primary data sources"
          - "Documented trusted source list with basic verification"
          - "Automated source verification with trust scoring and provenance tracking"
          - "Cryptographic verification with blockchain-based provenance and real-time trust assessment"
        help_text: "Evaluate source vetting, trust frameworks, provenance tracking, and verification methods"
      
      - id: "data_poisoning_q3"
        text: "Does your organization test AI systems for resilience against data poisoning attacks?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No poisoning attack testing performed"
          - "Occasional manual testing with known attack patterns"
          - "Regular testing with simulated poisoning scenarios"
          - "Comprehensive testing with automated attack simulation and red teaming"
          - "Continuous adversarial testing with adaptive attack generation"
        help_text: "Consider poisoning attack simulation, backdoor testing, and adversarial data injection"

    indicators:
      indicators:
        - "Data poisoning detection capabilities"
        - "Data source verification and trust scoring"
        - "Anomaly and outlier detection"
        - "Provenance tracking and chain of custody"
        - "Poisoning attack testing and resilience"
      
      definitions:
        level_1: "No awareness or protection against data poisoning attacks"
        level_2: "Basic data validation and manual review of training datasets"
        level_3: "Automated anomaly detection with statistical analysis for poisoning attempts"
        level_4: "Advanced prevention with provenance tracking, automated filtering, and attack simulation"
        level_5: "Adaptive defenses with ML-based detection, continuous monitoring, and self-healing datasets"
      
      success_criteria:
        - "Data poisoning detection accuracy above 95% with minimal false positives"
        - "Complete provenance tracking for 100% of training data sources"
        - "Automated poisoning attack testing in CI/CD pipeline"
        - "Zero successful data poisoning attacks in production models"
        - "Mean time to detect poisoning attempts under 24 hours"

  ai_red_teaming:
    id: "ai_red_teaming"
    name: "AI Red Teaming"
    description: "Adversarial testing and security assessment of AI systems through red team exercises"
    pillar: "security_for_ai"
    weight: 1.3

    key_controls:
      - "AI-specific red team methodology and frameworks"
      - "Regular adversarial testing of AI models and systems"
      - "Prompt injection and jailbreak testing"
      - "Model extraction and inversion attack simulation"
      - "Adversarial example generation and testing"
      - "Data poisoning and backdoor attack testing"
      - "AI system abuse and misuse testing"
      - "Purple team exercises with defensive teams"
      - "Red team findings remediation tracking"
    
    framework_alignment:
      - indicator: "AI red team program and methodology"
        frameworks:
          nist_ai_rmf: ["MEASURE 2.11", "MANAGE 4.1", "GOVERN 1.5"]
          iso_42001: ["8.7", "9.2"]
          nist_csf: ["DE.CM-4", "RS.AN-5"]
          mitre_atlas: ["AML.T0043 - Craft Adversarial Data", "AML.T0051 - LLM Jailbreak", "AML.T0054 - LLM Prompt Injection"]
          owasp_genai: ["LLM01:2025 Prompt Injection", "LLM04:2025 Data and Model Poisoning"]
      - indicator: "Adversarial testing for model robustness"
        frameworks:
          nist_ai_rmf: ["MEASURE 2.3", "MEASURE 2.11"]
          iso_42001: ["8.7"]
          mitre_atlas: ["AML.T0043 - Craft Adversarial Data", "AML.T0015 - Evade ML Model"]
          owasp_asvs: ["V14 - Configuration"]
      - indicator: "Prompt injection and jailbreak testing"
        frameworks:
          owasp_genai: ["LLM01:2025 Prompt Injection"]
          nist_ai_rmf: ["MEASURE 2.11", "MANAGE 2.3"]
          mitre_atlas: ["AML.T0051 - LLM Jailbreak", "AML.T0054 - LLM Prompt Injection"]
      - indicator: "Model extraction and inversion testing"
        frameworks:
          nist_ai_rmf: ["MEASURE 2.11", "MAP 3.4"]
          iso_42001: ["8.7"]
          mitre_atlas: ["AML.T0024 - Exfiltration via ML Inference API", "AML.T0044 - Full ML Model Access"]
          owasp_genai: ["LLM06:2025 Excessive Agency", "LLM08:2025 Vector and Embedding Weaknesses"]
      - indicator: "Purple team collaboration and remediation"
        frameworks:
          nist_ai_rmf: ["MANAGE 4.1", "MANAGE 4.2"]
          iso_27001: ["A.16.1.4", "A.16.1.5"]
          nist_csf: ["RS.IM-1", "RS.IM-2"]
    
    levels:
      level_1:
        level: "level_1"
        name: "No Red Teaming"
        description: "No adversarial testing or red team exercises for AI systems"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Ad-hoc Testing"
        description: "Occasional manual adversarial testing with basic attack scenarios"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Regular Red Teaming"
        description: "Regular red team exercises with documented methodology and comprehensive attack scenarios"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Automated & Advanced"
        description: "Automated red teaming with advanced attack techniques and continuous testing"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Adaptive Red Teaming"
        description: "AI-powered adaptive red teaming with purple team collaboration and real-time remediation"
        score_value: 5
    
    questions:
      - id: "ai_red_team_q1"
        text: "How often does your organization conduct red team exercises specifically for AI systems?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No AI-specific red team exercises conducted"
          - "Annual or ad-hoc testing when major changes occur"
          - "Quarterly red team exercises with documented scenarios"
          - "Monthly or continuous testing with automated tools"
          - "Continuous adaptive red teaming with real-time feedback and remediation"
        help_text: "Consider frequency, scope, and integration with development lifecycle"
      
      - id: "ai_red_team_q2"
        text: "What types of adversarial attacks does your AI red team test for?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No adversarial attack testing performed"
          - "Basic prompt injection and input manipulation testing"
          - "Comprehensive testing including jailbreaks, data poisoning, and adversarial examples"
          - "Advanced testing with model extraction, inversion, and membership inference attacks"
          - "Full spectrum testing with novel attack techniques and automated attack generation"
        help_text: "Consider prompt injection, jailbreaks, adversarial examples, model extraction, data poisoning, etc."
      
      - id: "ai_red_team_q3"
        text: "How does your organization track and remediate findings from AI red team exercises?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No formal tracking or remediation process"
          - "Manual documentation with ad-hoc remediation"
          - "Tracked in issue management system with assigned owners"
          - "Automated tracking with SLA-based remediation and verification"
          - "Real-time purple team collaboration with automated remediation and continuous validation"
        help_text: "Evaluate finding documentation, prioritization, remediation tracking, and verification processes"
      
      - id: "ai_red_team_q4"
        text: "Does your AI red team use automated tools and frameworks?"
        question_type: "single_choice"
        weight: 0.8
        required: true
        options:
          - "No automated red teaming tools used"
          - "Basic open-source tools for adversarial example generation"
          - "Commercial and open-source frameworks for comprehensive testing"
          - "Custom automated red teaming platform with CI/CD integration"
          - "AI-powered adaptive red teaming with self-evolving attack techniques"
        help_text: "Consider tools for adversarial testing, prompt injection, fuzzing, and attack automation"

    indicators:
      indicators:
        - "AI red team program maturity and methodology"
        - "Frequency and coverage of adversarial testing"
        - "Attack scenario breadth and sophistication"
        - "Automated red teaming capabilities"
        - "Purple team collaboration and remediation effectiveness"
      
      definitions:
        level_1: "No adversarial testing or red team exercises for AI systems"
        level_2: "Occasional manual adversarial testing with basic attack scenarios"
        level_3: "Regular red team exercises with documented methodology and comprehensive attack scenarios"
        level_4: "Automated red teaming with advanced attack techniques and continuous testing"
        level_5: "AI-powered adaptive red teaming with purple team collaboration and real-time remediation"
      
      success_criteria:
        - "Red team exercises conducted at least quarterly for all critical AI systems"
        - "Comprehensive coverage of OWASP Top 10 for LLM and MITRE ATLAS attack patterns"
        - "Mean time to remediate critical findings under 30 days"
        - "Automated red teaming integrated into CI/CD pipeline"
        - "100% of critical findings verified and closed before production deployment"

  # AI for Security Domains
  threat_detection_analysis:
    id: "threat_detection_analysis"
    name: "Threat Detection & Analysis"
    description: "AI-powered threat detection, analysis, and hunting capabilities"
    pillar: "ai_for_security"
    weight: 1.3

    key_controls:
      - "AI-specific threat modeling methodology"
      - "Model behavior monitoring and anomaly detection"
      - "Input validation and adversarial input detection"
      - "Output monitoring for data leakage and hallucinations"
      - "Integration with enterprise threat intelligence"
    
    framework_alignment:
      - indicator: "AI-powered log analysis and anomaly detection capabilities"
        frameworks:
          nist_csf: ["DE.AE-1", "DE.AE-3", "DE.CM-1"]
          iso_27001: ["A.12.4.1", "A.16.1.2"]
          soc2_security: ["CC7.1", "CC7.2"]
          iso_42001: ["8.6", "8.7", "9.1"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data", "AML.T0044 - Full ML Model Access"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Detection", "LLM04:2025 Data and Model Poisoning - Analysis"]
      - indicator: "Threat hunting automation and pattern recognition"
        frameworks:
          nist_csf: ["DE.DP-4", "DE.DP-5"]
          mitre_attack: ["TA0007", "TA0008"]
          iso_27001: ["A.16.1.4", "A.16.1.7"]
          iso_42001: ["8.3", "8.6", "8.7"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data", "AML.T0044 - Full ML Model Access"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Detection", "LLM04:2025 Data and Model Poisoning - Analysis"]
      - indicator: "Predictive threat intelligence and behavioral analysis"
        frameworks:
          nist_csf: ["DE.AE-2", "DE.CM-8"]
          iso_27001: ["A.12.2.1", "A.16.1.1"]
          mitre_attack: ["T1071", "T1078"]
          iso_42001: ["8.2.2", "8.6", "9.1"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data", "AML.T0044 - Full ML Model Access"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Detection", "LLM04:2025 Data and Model Poisoning - Analysis"]
      - indicator: "Real-time adaptive learning and model updating"
        frameworks:
          nist_csf: ["DE.CM-7", "RS.IM-1"]
          iso_27001: ["A.12.6.1", "Clause 10.1"]
          soc2_security: ["CC4.1", "CC7.4"]
          iso_42001: ["8.5.1", "9.3", "10.1"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data", "AML.T0044 - Full ML Model Access"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Detection", "LLM04:2025 Data and Model Poisoning - Analysis"]
      - indicator: "Integration with security infrastructure and workflows"
        frameworks:
          nist_csf: ["DE.CM-1", "RS.CO-2"]
          iso_27001: ["A.13.1.1", "A.16.1.5"]
          soc2_security: ["CC6.1", "CC6.8"]
          iso_42001: ["8.1", "8.3", "7.1.4"]
    
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data", "AML.T0044 - Full ML Model Access"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Detection", "LLM04:2025 Data and Model Poisoning - Analysis"]
    levels:
      level_1:
        level: "level_1"
        name: "Manual Analysis"
        description: "Manual threat analysis with no AI assistance"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Basic AI Analysis"
        description: "Basic AI-powered log analysis and anomaly detection"
        score_value: 2
      level_3:
        level: "level_3"
        name: "AI Threat Hunting"
        description: "AI-driven threat hunting with pattern recognition"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Predictive Intelligence"
        description: "Advanced AI threat intelligence with predictive capabilities"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Autonomous Detection"
        description: "Autonomous threat detection with self-learning AI systems"
        score_value: 5
    
    questions:
      - id: "threat_detection_q1"
        text: "How does your organization use AI for threat detection and analysis?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No AI used in threat detection - purely manual analysis"
          - "Basic AI tools for log analysis and simple anomaly detection"
          - "AI-powered threat hunting with pattern recognition capabilities"
          - "Advanced AI with predictive threat intelligence and behavioral analysis"
          - "Autonomous AI systems with self-learning and adaptive threat detection"
        help_text: "Consider AI usage across network monitoring, endpoint detection, and security analytics"
      
      - id: "threat_detection_q2"
        text: "What level of automation does your AI threat detection provide?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "Manual investigation of all alerts and anomalies"
          - "Automated alert generation with manual triage and analysis"
          - "Automated threat classification with guided investigation workflows"
          - "Automated threat analysis with contextual insights and recommendations"
          - "Fully automated threat detection with autonomous response capabilities"
        help_text: "Evaluate automation in alert generation, threat classification, investigation, and response"
      
      - id: "threat_detection_q3"
        text: "How well do your AI threat detection systems adapt to new attack patterns?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "Static rule-based detection with manual updates"
          - "Periodic model updates with threat intelligence feeds"
          - "Regular retraining with new attack data and patterns"
          - "Continuous learning with adaptive models and feedback loops"
          - "Real-time adaptation with autonomous model evolution and threat prediction"
        help_text: "Consider model retraining frequency, threat intelligence integration, and adaptive learning capabilities"

    indicators:
      indicators:
        - "AI-powered log analysis and anomaly detection capabilities"
        - "Threat hunting automation and pattern recognition"
        - "Predictive threat intelligence and behavioral analysis"
        - "Real-time adaptive learning and model updating"
        - "Integration with security infrastructure and workflows"
      
      definitions:
        level_1: "Manual threat analysis with no AI assistance or automation"
        level_2: "Basic AI tools for log analysis and simple anomaly detection"
        level_3: "AI-driven threat hunting with advanced pattern recognition capabilities"
        level_4: "Predictive AI threat intelligence with behavioral analysis and forecasting"
        level_5: "Autonomous threat detection with self-learning and adaptive AI systems"
      
      success_criteria:
        - "AI threat detection covers 100% of critical network and endpoint assets"
        - "Mean time to detection (MTTD) reduced by 80% through AI automation"
        - "False positive rates below 5% with continuous model improvement"
        - "Real-time threat hunting capabilities with predictive analysis"

  incident_response:
    id: "incident_response"
    name: "Incident Response"
    description: "AI-enhanced incident response and automation capabilities"
    pillar: "ai_for_security"
    weight: 1.2

    key_controls:
      - "AI-specific incident response playbooks"
      - "Model rollback and containment procedures"
      - "AI incident classification and severity criteria"
      - "Post-incident analysis for AI-specific attacks"
      - "Communication protocols for AI security incidents"
    
    framework_alignment:
      - indicator: "AI-assisted incident triage and classification capabilities"
        frameworks:
          nist_csf: ["RS.AN-1", "RS.AN-2"]
          iso_27001: ["A.16.1.2", "A.16.1.4"]
          nist_ir: ["PR.1", "AN.1"]
          iso_42001: ["8.6", "8.7", "10.2"]
          mitre_atlas: ["AML.T0048 - Exfiltration via ML Inference API", "AML.T0024 - Exfiltration via Cyber Means"]
          owasp_genai: ["LLM02:2025 Sensitive Information Disclosure - Response", "LLM06:2025 Excessive Agency - Containment"]
      - indicator: "Automated workflow orchestration and response coordination"
        frameworks:
          nist_csf: ["RS.RP-1", "RS.CO-1"]
          iso_27001: ["A.16.1.5", "A.16.1.6"]
          soc2_security: ["CC7.3", "CC7.4"]
          iso_42001: ["8.3", "8.5.2", "8.1"]
          mitre_atlas: ["AML.T0048 - Exfiltration via ML Inference API", "AML.T0024 - Exfiltration via Cyber Means"]
          owasp_genai: ["LLM02:2025 Sensitive Information Disclosure - Response", "LLM06:2025 Excessive Agency - Containment"]
      - indicator: "AI-powered root cause analysis and evidence correlation"
        frameworks:
          nist_csf: ["RS.AN-3", "RS.AN-4"]
          iso_27001: ["A.16.1.7", "A.16.1.4"]
          nist_ir: ["AN.2", "AN.3"]
          iso_42001: ["8.6", "8.7", "9.2"]
          mitre_atlas: ["AML.T0048 - Exfiltration via ML Inference API", "AML.T0024 - Exfiltration via Cyber Means"]
          owasp_genai: ["LLM02:2025 Sensitive Information Disclosure - Response", "LLM06:2025 Excessive Agency - Containment"]
      - indicator: "Autonomous decision-making and remediation actions"
        frameworks:
          nist_csf: ["RS.MI-1", "RS.MI-2"]
          iso_27001: ["A.16.1.5", "A.12.2.1"]
          soc2_security: ["CC7.2", "CC7.4"]
          iso_42001: ["8.5.2", "8.1", "5.2"]
          mitre_atlas: ["AML.T0048 - Exfiltration via ML Inference API", "AML.T0024 - Exfiltration via Cyber Means"]
          owasp_genai: ["LLM02:2025 Sensitive Information Disclosure - Response", "LLM06:2025 Excessive Agency - Containment"]
      - indicator: "Continuous learning from incident patterns and outcomes"
        frameworks:
          nist_csf: ["RS.IM-1", "RS.IM-2"]
          iso_27001: ["A.16.1.6", "Clause 10.1"]
          nist_ir: ["IM.1", "IM.2"]
          iso_42001: ["9.3", "10.1", "8.5.1"]
    
          mitre_atlas: ["AML.T0048 - Exfiltration via ML Inference API", "AML.T0024 - Exfiltration via Cyber Means"]
          owasp_genai: ["LLM02:2025 Sensitive Information Disclosure - Response", "LLM06:2025 Excessive Agency - Containment"]
    levels:
      level_1:
        level: "level_1"
        name: "Manual Response"
        description: "Manual incident response processes"
        score_value: 1
      level_2:
        level: "level_2"
        name: "AI-Assisted Triage"
        description: "AI-assisted incident triage and classification"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Automated Workflows"
        description: "Automated incident response workflows with AI orchestration"
        score_value: 3
      level_4:
        level: "level_4"
        name: "AI Analysis"
        description: "AI-powered root cause analysis and remediation recommendations"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Autonomous Response"
        description: "Fully autonomous incident response with AI decision-making"
        score_value: 5
    
    questions:
      - id: "incident_response_q1"
        text: "How does your organization use AI in incident response processes?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "Completely manual incident response with no AI assistance"
          - "AI assists with incident triage and initial classification"
          - "AI orchestrates automated workflows for standard incident types"
          - "AI provides root cause analysis and generates remediation recommendations"
          - "Fully autonomous incident response with AI-driven decision making"
        help_text: "Consider AI usage in detection, triage, investigation, containment, and recovery phases"
      
      - id: "incident_response_q2"
        text: "What level of automation does your AI-enhanced incident response provide?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "Manual execution of all incident response activities"
          - "Automated alert correlation and basic incident creation"
          - "Automated initial response actions for common incident types"
          - "Automated investigation with intelligent evidence gathering"
          - "End-to-end automation from detection through resolution"
        help_text: "Evaluate automation in containment, investigation, evidence collection, and remediation"
      
      - id: "incident_response_q3"
        text: "How well does your AI incident response system learn from past incidents?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No systematic learning from incident history"
          - "Basic incident data collection for manual analysis"
          - "Pattern analysis to improve future incident classification"
          - "Machine learning from incident outcomes to optimize response strategies"
          - "Continuous learning with predictive capabilities and preemptive actions"
        help_text: "Consider post-incident analysis, pattern recognition, and improvement of response procedures"

    indicators:
      indicators:
        - "AI-assisted incident triage and classification capabilities"
        - "Automated workflow orchestration and response coordination"
        - "AI-powered root cause analysis and evidence correlation"
        - "Autonomous decision-making and remediation actions"
        - "Continuous learning from incident patterns and outcomes"
      
      definitions:
        level_1: "Completely manual incident response with no AI assistance"
        level_2: "AI assists with incident triage and initial classification processes"
        level_3: "Automated workflows with AI orchestration for standard incident types"
        level_4: "AI provides comprehensive root cause analysis and remediation recommendations"
        level_5: "Fully autonomous incident response with AI-driven decision making"
      
      success_criteria:
        - "Mean time to response (MTTR) reduced by 70% through AI automation"
        - "Incident classification accuracy above 95% with AI assistance"
        - "Automated containment for 80% of standard incident types"
        - "Continuous improvement in response effectiveness through AI learning"

  vulnerability_management:
    id: "vulnerability_management"
    name: "Vulnerability Management"
    description: "AI-driven vulnerability assessment, prioritization, and management"
    pillar: "ai_for_security"
    weight: 1.1

    key_controls:
      - "AI/ML-specific vulnerability scanning and assessment"
      - "Model robustness testing against adversarial attacks"
      - "Dependency vulnerability tracking for ML frameworks"
      - "Vulnerability prioritization criteria for AI systems"
      - "Remediation SLAs for AI vulnerabilities"
    
    framework_alignment:
      - indicator: "AI-enhanced vulnerability prioritization and risk scoring"
        frameworks:
          nist_csf: ["ID.RA-1", "ID.RA-2"]
          iso_27001: ["A.12.6.1", "A.18.2.2"]
          cvss: ["Base.Score", "Temporal.Score"]
          iso_42001: ["8.6", "8.7", "6.1"]
          mitre_atlas: ["AML.T0010 - ML Supply Chain Compromise", "AML.T0043 - Craft Adversarial Data"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities", "LLM04:2025 Data and Model Poisoning - Assessment"]
      - indicator: "Automated vulnerability assessment and discovery capabilities"
        frameworks:
          nist_csf: ["DE.CM-4", "ID.AM-4"]
          iso_27001: ["A.12.6.1", "A.14.2.1"]
          owasp_asvs: ["V1.14", "V14.1"]
          iso_42001: ["8.2.2", "8.6", "8.3"]
          mitre_atlas: ["AML.T0010 - ML Supply Chain Compromise", "AML.T0043 - Craft Adversarial Data"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities", "LLM04:2025 Data and Model Poisoning - Assessment"]
      - indicator: "Predictive vulnerability identification and threat modeling"
        frameworks:
          nist_csf: ["ID.RA-3", "PR.IP-12"]
          iso_27001: ["A.14.2.1", "A.12.6.1"]
          stride: ["Spoofing", "Tampering"]
          iso_42001: ["6.1", "8.2.2", "8.6"]
          mitre_atlas: ["AML.T0010 - ML Supply Chain Compromise", "AML.T0043 - Craft Adversarial Data"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities", "LLM04:2025 Data and Model Poisoning - Assessment"]
      - indicator: "Threat intelligence integration and dynamic risk analysis"
        frameworks:
          nist_csf: ["DE.CM-8", "ID.RA-2"]
          iso_27001: ["A.12.2.1", "A.16.1.3"]
          stix_taxii: ["Indicator", "TTP"]
          iso_42001: ["8.6", "8.7", "9.1"]
          mitre_atlas: ["AML.T0010 - ML Supply Chain Compromise", "AML.T0043 - Craft Adversarial Data"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities", "LLM04:2025 Data and Model Poisoning - Assessment"]
      - indicator: "Automated patch management and verification processes"
        frameworks:
          nist_csf: ["PR.IP-12", "DE.CM-4"]
          iso_27001: ["A.12.6.1", "A.14.2.3"]
          soc2_security: ["CC6.1", "CC8.1"]
          iso_42001: ["8.5.2", "8.6", "9.2"]
    
          mitre_atlas: ["AML.T0010 - ML Supply Chain Compromise", "AML.T0043 - Craft Adversarial Data"]
          owasp_genai: ["LLM03:2025 Supply Chain Vulnerabilities", "LLM04:2025 Data and Model Poisoning - Assessment"]
    levels:
      level_1:
        level: "level_1"
        name: "Manual Assessment"
        description: "Manual vulnerability scanning and assessment"
        score_value: 1
      level_2:
        level: "level_2"
        name: "AI Prioritization"
        description: "AI-enhanced vulnerability prioritization"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Automated Assessment"
        description: "Automated vulnerability assessment with AI risk scoring"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Predictive Management"
        description: "AI-driven vulnerability prediction and proactive patching"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Continuous AI Management"
        description: "Continuous AI-powered vulnerability lifecycle management"
        score_value: 5
    
    questions:
      - id: "vuln_mgmt_q1"
        text: "How does your organization use AI in vulnerability management?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "Manual vulnerability scanning and assessment only"
          - "AI helps prioritize vulnerabilities based on risk factors"
          - "Automated AI-driven vulnerability assessment and risk scoring"
          - "Predictive AI that identifies likely vulnerabilities before exploitation"
          - "Continuous AI management with autonomous patch deployment and risk mitigation"
        help_text: "Consider AI usage in discovery, assessment, prioritization, and remediation phases"
      
      - id: "vuln_mgmt_q2"
        text: "How well does your AI vulnerability management integrate threat intelligence?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No integration of threat intelligence with vulnerability data"
          - "Basic correlation of vulnerabilities with known threat indicators"
          - "AI analysis combining vulnerability data with threat intelligence feeds"
          - "Dynamic risk scoring based on real-time threat landscape analysis"
          - "Predictive threat modeling with automated prioritization and response"
        help_text: "Evaluate integration with external threat feeds, exploitation likelihood, and attack trend analysis"
      
      - id: "vuln_mgmt_q3"
        text: "What level of automation does your AI vulnerability management provide?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "Manual tracking and remediation of all vulnerabilities"
          - "Automated vulnerability scanning with manual remediation planning"
          - "Automated remediation workflows for low-risk vulnerabilities"
          - "AI-driven remediation planning with contextual business impact analysis"
          - "Fully automated vulnerability lifecycle with autonomous patching and verification"
        help_text: "Consider automation in scanning, assessment, patch management, and verification processes"

    indicators:
      indicators:
        - "AI-enhanced vulnerability prioritization and risk scoring"
        - "Automated vulnerability assessment and discovery capabilities"
        - "Predictive vulnerability identification and threat modeling"
        - "Threat intelligence integration and dynamic risk analysis"
        - "Automated patch management and verification processes"
      
      definitions:
        level_1: "Manual vulnerability scanning and assessment without AI assistance"
        level_2: "AI helps prioritize vulnerabilities based on multiple risk factors"
        level_3: "Automated AI-driven vulnerability assessment with intelligent risk scoring"
        level_4: "Predictive AI that identifies vulnerabilities before exploitation occurs"
        level_5: "Continuous AI management with autonomous patching and risk mitigation"
      
      success_criteria:
        - "Vulnerability identification accuracy improved by 60% with AI"
        - "Mean time to patch (MTTP) reduced by 50% through automation"
        - "Risk scoring accuracy above 90% with threat intelligence integration"
        - "Proactive vulnerability prevention through predictive modeling"

  identity_access_management:
    id: "identity_access_management"
    name: "Identity & Access Management"
    description: "AI-enhanced identity governance and access control systems"
    pillar: "ai_for_security"
    weight: 1.0

    key_controls:
      - "Least privilege access for ML systems and data"
      - "API key and credential management for AI services"
      - "Role-based access control for model management"
      - "Audit logging for AI system access"
      - "Service account management for ML pipelines"
    
    framework_alignment:
      - indicator: "AI-powered user behavior analytics and anomaly detection"
        frameworks:
          nist_csf: ["DE.AE-2", "DE.CM-1"]
          iso_27001: ["A.9.2.5", "A.12.4.1"]
          zero_trust: ["Identity.1", "Identity.3"]
          iso_42001: ["8.6", "8.7", "9.1"]
          mitre_atlas: ["AML.T0044 - Full ML Model Access", "AML.T0048 - Exfiltration via ML Inference API"]
          owasp_genai: ["LLM06:2025 Excessive Agency - Access Controls", "LLM02:2025 Sensitive Information Disclosure - IAM"]
      - indicator: "Adaptive authentication with risk-based access decisions"
        frameworks:
          nist_csf: ["PR.AC-1", "PR.AC-7"]
          iso_27001: ["A.9.1.2", "A.9.4.2"]
          nist_800_63: ["AAL2", "AAL3"]
          iso_42001: ["8.5.2", "8.2.2", "7.1.4"]
          mitre_atlas: ["AML.T0044 - Full ML Model Access", "AML.T0048 - Exfiltration via ML Inference API"]
          owasp_genai: ["LLM06:2025 Excessive Agency - Access Controls", "LLM02:2025 Sensitive Information Disclosure - IAM"]
      - indicator: "Zero-trust architecture with continuous access validation"
        frameworks:
          zero_trust: ["Identity.2", "Network.1"]
          nist_csf: ["PR.AC-4", "DE.CM-1"]
          iso_27001: ["A.9.1.2", "A.13.1.1"]
          iso_42001: ["8.1", "8.5.2", "8.6"]
          mitre_atlas: ["AML.T0044 - Full ML Model Access", "AML.T0048 - Exfiltration via ML Inference API"]
          owasp_genai: ["LLM06:2025 Excessive Agency - Access Controls", "LLM02:2025 Sensitive Information Disclosure - IAM"]
      - indicator: "Automated access governance and entitlement management"
        frameworks:
          iso_27001: ["A.9.2.1", "A.9.2.6"]
          nist_csf: ["PR.AC-1", "ID.AM-6"]
          soc2_security: ["CC6.2", "CC6.3"]
          iso_42001: ["8.1", "8.3", "7.1.4"]
          mitre_atlas: ["AML.T0044 - Full ML Model Access", "AML.T0048 - Exfiltration via ML Inference API"]
          owasp_genai: ["LLM06:2025 Excessive Agency - Access Controls", "LLM02:2025 Sensitive Information Disclosure - IAM"]
      - indicator: "Predictive identity threat prevention and response"
        frameworks:
          nist_csf: ["DE.AE-1", "RS.AN-1"]
          iso_27001: ["A.16.1.2", "A.9.2.5"]
          mitre_attack: ["T1078", "T1534"]
          iso_42001: ["8.6", "8.7", "10.2"]
    
          mitre_atlas: ["AML.T0044 - Full ML Model Access", "AML.T0048 - Exfiltration via ML Inference API"]
          owasp_genai: ["LLM06:2025 Excessive Agency - Access Controls", "LLM02:2025 Sensitive Information Disclosure - IAM"]
    levels:
      level_1:
        level: "level_1"
        name: "Traditional Controls"
        description: "Traditional rule-based access controls"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Behavioral Analytics"
        description: "AI-enhanced user behavior analytics"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Adaptive Authentication"
        description: "Adaptive authentication with AI risk assessment"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Zero-Trust AI"
        description: "AI-driven zero-trust access decisions"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Autonomous Governance"
        description: "Autonomous identity governance with AI-powered access optimization"
        score_value: 5
    
    questions:
      - id: "iam_q1"
        text: "How does your organization use AI in identity and access management?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "Traditional rule-based access controls with no AI enhancement"
          - "AI-powered user behavior analytics for anomaly detection"
          - "Adaptive authentication using AI risk assessment and context analysis"
          - "Zero-trust architecture with AI-driven continuous access decisions"
          - "Autonomous identity governance with AI-optimized access provisioning and management"
        help_text: "Consider AI usage in authentication, authorization, user behavior analysis, and access governance"
      
      - id: "iam_q2"
        text: "How well does your AI-enhanced IAM system detect and respond to identity threats?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No AI-based identity threat detection capabilities"
          - "Basic behavioral analytics with manual investigation of anomalies"
          - "Automated detection of identity-based threats with alert generation"
          - "Real-time threat detection with automated response and account protection"
          - "Predictive identity threat prevention with proactive risk mitigation"
        help_text: "Evaluate detection of compromised accounts, insider threats, and privileged access abuse"
      
      - id: "iam_q3"
        text: "What level of automation does your AI IAM system provide for access governance?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "Manual access reviews and provisioning processes"
          - "AI-assisted access reviews with manual approval workflows"
          - "Automated access provisioning based on AI role and pattern analysis"
          - "Dynamic access adjustment with AI-driven risk-based decisions"
          - "Fully autonomous access governance with continuous optimization and compliance"
        help_text: "Consider automation in access reviews, provisioning, deprovisioning, and entitlement management"

    indicators:
      indicators:
        - "AI-powered user behavior analytics and anomaly detection"
        - "Adaptive authentication with risk-based access decisions"
        - "Zero-trust architecture with continuous access validation"
        - "Automated access governance and entitlement management"
        - "Predictive identity threat prevention and response"
      
      definitions:
        level_1: "Traditional rule-based access controls with no AI enhancement"
        level_2: "AI-powered user behavior analytics for anomaly detection"
        level_3: "Adaptive authentication using AI risk assessment and context analysis"
        level_4: "Zero-trust architecture with AI-driven continuous access decisions"
        level_5: "Autonomous identity governance with AI-optimized access management"
      
      success_criteria:
        - "Identity threat detection accuracy above 95% with minimal false positives"
        - "Adaptive authentication reduces security incidents by 60%"
        - "Automated access governance with 100% compliance tracking"
        - "Real-time risk-based access decisions for all users and resources"

  security_operations:
    id: "security_operations"
    name: "Security Operations"
    description: "AI-powered security operations center (SOC) capabilities"
    pillar: "ai_for_security"
    weight: 1.2

    key_controls:
      - "AI system monitoring in security operations center"
      - "Automated alerting for AI security anomalies"
      - "Integration of AI telemetry into SIEM"
      - "24/7 monitoring coverage for critical AI systems"
      - "Runbooks for common AI security scenarios"
    
    framework_alignment:
      - indicator: "AI-powered event correlation and alert prioritization"
        frameworks:
          nist_csf: ["DE.AE-1", "DE.AE-3"]
          iso_27001: ["A.12.4.1", "A.16.1.2"]
          soc2_security: ["CC7.1", "CC7.2"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0048 - Exfiltration via ML Inference API"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Monitoring", "LLM08:2025 Vector and Embedding Weaknesses - Operations"]
      - indicator: "Automated security workflow orchestration and SOAR integration"
        frameworks:
          nist_csf: ["RS.RP-1", "RS.CO-1"]
          iso_27001: ["A.16.1.5", "A.13.1.1"]
          soc2_security: ["CC7.3", "CC7.4"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0048 - Exfiltration via ML Inference API"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Monitoring", "LLM08:2025 Vector and Embedding Weaknesses - Operations"]
      - indicator: "AI-driven security analytics and threat intelligence integration"
        frameworks:
          nist_csf: ["DE.CM-8", "DE.DP-4"]
          iso_27001: ["A.12.2.1", "A.16.1.3"]
          mitre_attack: ["TA0001", "TA0043"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0048 - Exfiltration via ML Inference API"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Monitoring", "LLM08:2025 Vector and Embedding Weaknesses - Operations"]
      - indicator: "Automated incident classification and response recommendations"
        frameworks:
          nist_csf: ["RS.AN-1", "RS.MI-1"]
          iso_27001: ["A.16.1.4", "A.16.1.5"]
          nist_ir: ["PR.1", "AN.1"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0048 - Exfiltration via ML Inference API"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Monitoring", "LLM08:2025 Vector and Embedding Weaknesses - Operations"]
      - indicator: "Continuous security monitoring with predictive capabilities"
        frameworks:
          nist_csf: ["DE.CM-1", "DE.CM-7"]
          iso_27001: ["A.12.4.1", "Clause 9.1"]
          soc2_security: ["CC7.1", "CC4.1"]
    
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0048 - Exfiltration via ML Inference API"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Monitoring", "LLM08:2025 Vector and Embedding Weaknesses - Operations"]
    levels:
      level_1:
        level: "level_1"
        name: "Manual Operations"
        description: "Manual security monitoring and analysis"
        score_value: 1
      level_2:
        level: "level_2"
        name: "AI-Assisted Correlation"
        description: "AI-assisted security event correlation"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Automated Operations"
        description: "Automated security operations with AI workflow orchestration"
        score_value: 3
      level_4:
        level: "level_4"
        name: "AI Decision Support"
        description: "AI-powered security decision support systems"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Autonomous SOC"
        description: "Fully autonomous security operations center (AI-SOC)"
        score_value: 5
    
    questions:
      - id: "sec_ops_q1"
        text: "How does your organization use AI in security operations center (SOC) activities?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "Manual security monitoring and analysis with no AI assistance"
          - "AI assists with security event correlation and basic pattern recognition"
          - "Automated security workflows with AI orchestration and intelligent routing"
          - "AI-powered decision support with contextual analysis and recommendations"
          - "Fully autonomous SOC with AI handling end-to-end security operations"
        help_text: "Consider AI usage in monitoring, correlation, investigation, and response activities"
      
      - id: "sec_ops_q2"
        text: "What level of automation does your AI-powered SOC provide?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "Manual review and response to all security events"
          - "Automated alert generation with manual triage and investigation"
          - "Automated investigation workflows with AI-guided analysis"
          - "Automated response actions with AI-driven decision making"
          - "End-to-end automation from detection through resolution and learning"
        help_text: "Evaluate automation in event processing, investigation, containment, and remediation"
      
      - id: "sec_ops_q3"
        text: "How well does your AI SOC system adapt and improve over time?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "Static rules and procedures with manual updates"
          - "Periodic model updates based on analyst feedback"
          - "Regular learning from security events and outcomes"
          - "Continuous learning with adaptive playbooks and automated improvements"
          - "Self-evolving AI systems with predictive capabilities and proactive optimization"
        help_text: "Consider continuous learning, feedback integration, and adaptive security procedures"

    indicators:
      indicators:
        - "AI-assisted security event correlation and analysis"
        - "Automated workflow orchestration and intelligent routing"
        - "AI-powered decision support and contextual recommendations"
        - "Autonomous security operations and response capabilities"
        - "Continuous learning and adaptive security procedures"
      
      definitions:
        level_1: "Manual security monitoring and analysis with no AI assistance"
        level_2: "AI assists with security event correlation and basic pattern recognition"
        level_3: "Automated security workflows with AI orchestration and intelligent routing"
        level_4: "AI-powered decision support with contextual analysis and recommendations"
        level_5: "Fully autonomous SOC with AI handling end-to-end security operations"
      
      success_criteria:
        - "Security event processing speed increased by 90% with AI automation"
        - "Mean time to investigation (MTTI) reduced by 75% through AI assistance"
        - "SOC analyst productivity improved by 300% with AI decision support"
        - "Autonomous handling of 70% of routine security operations"

  fraud_detection:
    id: "fraud_detection"
    name: "Fraud Detection"
    description: "AI-powered fraud detection and prevention systems for financial transactions, account security, and payment protection"
    pillar: "ai_for_security"
    weight: 1.2

    key_controls:
      - "AI-powered fraud detection model security"
      - "Adversarial testing of fraud detection models"
      - "Model retraining procedures when evasion detected"
      - "Human-in-the-loop for high-confidence fraud cases"
      - "Feedback loop for fraud model improvement"
      - "Real-time transaction monitoring and risk scoring"
      - "Account takeover detection using behavioral biometrics"
      - "Payment fraud detection across multiple channels"
      - "Identity verification and synthetic identity detection"
      - "Money laundering pattern detection and AML compliance"
      - "Cross-channel fraud correlation and investigation"
      - "Merchant fraud and chargeback prevention"
      - "Model explainability for regulatory compliance"
      - "Fraud model performance monitoring and drift detection"
    
    framework_alignment:
      - indicator: "AI-powered transaction analysis and anomaly detection"
        frameworks:
          pci_dss: ["Requirement 11", "Requirement 12.10"]
          iso_27001: ["A.12.4.1", "A.16.1.2"]
          nist_csf: ["DE.AE-2", "DE.CM-1"]
          iso_42001: ["8.6", "8.7", "9.1"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data", "AML.T0031 - Erode ML Model Integrity"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Anti-Fraud", "LLM04:2025 Data and Model Poisoning - Fraud Models"]
      - indicator: "Real-time fraud scoring and risk assessment"
        frameworks:
          ffiec_guidance: ["Risk.Assessment", "Real.Time.Monitoring"]
          iso_27001: ["A.18.2.2", "A.12.1.4"]
          soc2_security: ["CC7.1", "CC4.1"]
          iso_42001: ["8.2.2", "8.6", "6.1"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data", "AML.T0031 - Erode ML Model Integrity"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Anti-Fraud", "LLM04:2025 Data and Model Poisoning - Fraud Models"]
      - indicator: "Behavioral pattern analysis and user profiling"
        frameworks:
          nist_csf: ["DE.AE-2", "ID.AM-6"]
          gdpr: ["Article 22", "Article 13"]
          iso_27001: ["A.9.2.5", "A.18.1.4"]
          iso_42001: ["8.6", "8.7", "5.2"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data", "AML.T0031 - Erode ML Model Integrity"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Anti-Fraud", "LLM04:2025 Data and Model Poisoning - Fraud Models"]
      - indicator: "Machine learning model performance and accuracy tracking"
        frameworks:
          model_risk_management: ["MRM.1", "MRM.3"]
          iso_27001: ["Clause 9.1", "A.12.1.4"]
          soc2_security: ["CC4.1", "CC4.2"]
          iso_42001: ["8.6", "9.1", "9.2"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data", "AML.T0031 - Erode ML Model Integrity"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Anti-Fraud", "LLM04:2025 Data and Model Poisoning - Fraud Models"]
      - indicator: "Integration with payment processing and financial systems"
        frameworks:
          pci_dss: ["Requirement 1", "Requirement 6"]
          iso_27001: ["A.13.1.1", "A.14.1.3"]
          ffiec_guidance: ["System.Integration", "API.Security"]
          iso_42001: ["8.1", "8.3", "7.1.4"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data", "AML.T0031 - Erode ML Model Integrity"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Anti-Fraud", "LLM04:2025 Data and Model Poisoning - Fraud Models"]
      - indicator: "Account takeover and credential abuse detection"
        frameworks:
          nist_csf: ["PR.AC-1", "DE.CM-1"]
          pci_dss: ["Requirement 8", "Requirement 10"]
          iso_27001: ["A.9.4.3", "A.12.4.1"]
          iso_42001: ["8.6", "8.7"]
          mitre_atlas: ["AML.T0015 - Evade ML Model"]
          owasp_genai: ["LLM01:2025 Prompt Injection - Anti-Fraud"]
      - indicator: "Anti-money laundering (AML) and suspicious activity detection"
        frameworks:
          ffiec_guidance: ["BSA.AML", "Suspicious.Activity.Reporting"]
          fatf_recommendations: ["Recommendation 1", "Recommendation 10"]
          iso_27001: ["A.18.1.5"]
          iso_42001: ["8.6", "5.2"]
    
    levels:
      level_1:
        level: "level_1"
        name: "Rule-Based Detection"
        description: "Basic rule-based fraud detection with static thresholds and manual review"
        score_value: 1
      level_2:
        level: "level_2"
        name: "AI Pattern Recognition"
        description: "AI-enhanced fraud pattern recognition with supervised learning on known fraud types"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Real-time AI Scoring"
        description: "Real-time AI fraud scoring with dynamic risk assessment and automated actions"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Behavioral Analysis"
        description: "Advanced AI behavioral analysis with unsupervised learning and cross-channel correlation"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Predictive Prevention"
        description: "Predictive AI fraud prevention with continuous learning, graph analytics, and proactive risk mitigation"
        score_value: 5
    
    questions:
      - id: "fraud_detection_q1"
        text: "How does your organization use AI for fraud detection and prevention?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "Traditional rule-based fraud detection systems only"
          - "AI-enhanced pattern recognition to identify known fraud signatures"
          - "Real-time AI scoring with dynamic risk assessment for transactions"
          - "Advanced behavioral analysis using AI to detect subtle fraud patterns"
          - "Predictive AI fraud prevention with continuous learning and adaptive models"
        help_text: "Consider AI usage across transaction monitoring, identity verification, and behavioral analysis"
      
      - id: "fraud_detection_q2"
        text: "What is the accuracy and false positive rate of your AI fraud detection system?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "High false positive rates requiring significant manual review"
          - "Moderate accuracy with some false positives but manageable review workload"
          - "Good accuracy with low false positive rates and efficient investigations"
          - "High accuracy with minimal false positives and intelligent case prioritization"
          - "Exceptional accuracy with predictive capabilities and near-zero false positives"
        help_text: "Evaluate detection accuracy, false positive management, and investigation efficiency"
      
      - id: "fraud_detection_q3"
        text: "How well does your AI fraud detection system adapt to new fraud techniques?"
        question_type: "single_choice"
        weight: 0.8
        required: true
        options:
          - "Manual rule updates when new fraud patterns are discovered"
          - "Periodic model retraining with new fraud data"
          - "Regular adaptive learning with feedback from investigations"
          - "Continuous learning with real-time model updates and threat intelligence"
          - "Autonomous adaptation with predictive modeling of emerging fraud trends"
        help_text: "Consider model adaptability, threat intelligence integration, and emerging fraud pattern detection"
      
      - id: "fraud_detection_q4"
        text: "What types of fraud does your AI system detect? (Select all that apply)"
        question_type: "multiple_choice"
        weight: 0.9
        required: true
        options:
          - code: "payment_fraud"
            label: "Payment and transaction fraud"
          - code: "account_takeover"
            label: "Account takeover and credential abuse"
          - code: "identity_theft"
            label: "Identity theft and synthetic identity fraud"
          - code: "money_laundering"
            label: "Money laundering and suspicious activity"
          - code: "merchant_fraud"
            label: "Merchant fraud and chargeback abuse"
          - code: "internal_fraud"
            label: "Internal fraud and employee misconduct"
          - code: "application_fraud"
            label: "Application fraud and loan fraud"
        help_text: "Select all fraud types that your AI system is designed to detect"
      
      - id: "fraud_detection_q5"
        text: "How does your organization handle false positives in AI fraud detection?"
        question_type: "single_choice"
        weight: 0.7
        required: true
        options:
          - "Manual review of all flagged transactions with high customer friction"
          - "Basic triage with some automated clearance for low-risk false positives"
          - "Intelligent case routing with explainable AI and streamlined customer experience"
          - "Advanced false positive reduction with continuous model tuning and feedback loops"
          - "Near-zero false positives with self-correcting models and frictionless customer experience"
        help_text: "Evaluate false positive management, customer impact, and operational efficiency"
      
      - id: "fraud_detection_q6"
        text: "What percentage of fraudulent transactions does your AI system successfully prevent?"
        question_type: "numeric"
        weight: 1.0
        required: true
        help_text: "Enter the percentage (0-100) of fraud attempts that are successfully detected and prevented. Consider both known and novel fraud patterns."
      
      - id: "fraud_detection_q7"
        text: "How does your organization ensure AI fraud models remain explainable and compliant?"
        question_type: "single_choice"
        weight: 0.8
        required: true
        options:
          - "Limited or no model explainability; black-box AI systems"
          - "Basic feature importance and post-hoc explanation capabilities"
          - "Good model interpretability with audit trails for regulatory compliance"
          - "Advanced explainable AI with case-level justifications and regulatory reporting"
          - "Full transparency with interpretable models, automated compliance reporting, and regulatory approval"
        help_text: "Consider model explainability, audit requirements, and regulatory compliance (e.g., FCRA, ECOA, GDPR)"

    indicators:
      indicators:
        - "AI-enhanced fraud pattern recognition and signature detection"
        - "Real-time fraud scoring and risk assessment capabilities"
        - "Advanced behavioral analysis and anomaly detection"
        - "Predictive fraud prevention and proactive risk mitigation"
        - "Continuous learning and adaptive model improvement"
        - "Cross-channel fraud correlation and investigation"
        - "Account takeover and identity fraud detection"
        - "AML and money laundering pattern detection"
      
      definitions:
        level_1: "Traditional rule-based fraud detection systems without AI enhancement; high false positives"
        level_2: "AI-enhanced pattern recognition to identify known fraud signatures; moderate accuracy"
        level_3: "Real-time AI scoring with dynamic risk assessment for transactions; good accuracy"
        level_4: "Advanced behavioral analysis using AI to detect subtle fraud patterns; high accuracy"
        level_5: "Predictive AI fraud prevention with continuous learning and proactive mitigation; exceptional accuracy"
      
      success_criteria:
        - "Fraud detection accuracy above 98% with false positive rate below 2%"
        - "Real-time transaction scoring with sub-second response times"
        - "Behavioral analysis detects 95% of account takeover attempts"
        - "Continuous adaptation to new fraud techniques within 24 hours"
        - "AML detection rate above 90% with automated SAR filing support"
        - "Customer friction reduced by 60% through intelligent false positive management"
        - "Model explainability meets regulatory requirements for all markets"

  # Security from AI Domains
  ai_content_detection:
    id: "ai_content_detection"
    name: "AI-Generated Content Detection"
    description: "Detection and verification of AI-generated content across multiple modalities"
    pillar: "security_from_ai"
    weight: 1.2

    key_controls:
      - "AI-generated content identification capabilities"
      - "Deepfake and synthetic media detection tools"
      - "Content authenticity verification procedures"
      - "Integration with content moderation workflows"
      - "Regular model updates for emerging generation techniques"
    
    framework_alignment:
      - indicator: "Text-based AI content detection and verification capabilities"
        frameworks:
          c2pa: ["Content.Provenance", "Content.Authenticity"]
          iso_27001: ["A.13.2.1", "A.16.1.2"]
          nist_csf: ["DE.AE-2", "PR.DS-6"]
          iso_42001: ["8.6", "8.7", "5.2"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data"]
          owasp_genai: ["LLM09:2025 Misinformation - Detection", "LLM05:2025 Improper Output Handling - Content Validation"]
      - indicator: "Multi-modal AI content detection (images, video, audio)"
        frameworks:
          c2pa: ["Image.Authentication", "Video.Authentication"]
          deepfake_detection: ["Detection.Accuracy", "Multi.Modal"]
          iso_27001: ["A.13.2.3", "A.14.1.2"]
          iso_42001: ["8.2.2", "8.6", "8.7"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data"]
          owasp_genai: ["LLM09:2025 Misinformation - Detection", "LLM05:2025 Improper Output Handling - Content Validation"]
      - indicator: "Integration with content management and publishing systems"
        frameworks:
          iso_27001: ["A.13.1.1", "A.14.1.3"]
          nist_csf: ["PR.IP-1", "DE.CM-1"]
          content_authenticity: ["CAI.1", "CAI.2"]
          iso_42001: ["8.1", "8.3", "7.1.4"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data"]
          owasp_genai: ["LLM09:2025 Misinformation - Detection", "LLM05:2025 Improper Output Handling - Content Validation"]
      - indicator: "Real-time content verification and authenticity scoring"
        frameworks:
          c2pa: ["Real.Time.Verification", "Provenance.Chain"]
          iso_27001: ["A.12.4.1", "A.16.1.2"]
          nist_csf: ["DE.CM-7", "PR.DS-6"]
          iso_42001: ["8.6", "9.1", "8.2.2"]
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data"]
          owasp_genai: ["LLM09:2025 Misinformation - Detection", "LLM05:2025 Improper Output Handling - Content Validation"]
      - indicator: "Policy enforcement and automated content flagging"
        frameworks:
          iso_27001: ["A.13.1.3", "A.18.1.4"]
          nist_csf: ["PR.AC-4", "RS.MI-1"]
          content_moderation: ["Policy.Enforcement", "Automated.Flagging"]
          iso_42001: ["8.5.2", "5.2", "8.1"]
    
          mitre_atlas: ["AML.T0015 - Evade ML Model", "AML.T0043 - Craft Adversarial Data"]
          owasp_genai: ["LLM09:2025 Misinformation - Detection", "LLM05:2025 Improper Output Handling - Content Validation"]
    levels:
      level_1:
        level: "level_1"
        name: "No Detection"
        description: "No capability to detect AI-generated content"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Basic Detection"
        description: "Basic tools to identify obvious AI-generated text/media"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Advanced Detection"
        description: "Advanced detection of sophisticated AI-generated content"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Multi-modal Detection"
        description: "Multi-modal AI content detection with high accuracy"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Real-time Authentication"
        description: "Real-time AI content authentication and provenance tracking"
        score_value: 5
    
    questions:
      - id: "ai_content_q1"
        text: "What capabilities does your organization have to detect AI-generated content?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No tools or capabilities to detect AI-generated content"
          - "Basic detection tools for obvious AI-generated text or simple media"
          - "Advanced detection capabilities for sophisticated AI-generated content"
          - "Multi-modal detection across text, images, audio, and video content"
          - "Real-time authentication with provenance tracking and content verification"
        help_text: "Consider detection across text, images, audio, video, and code generation"
      
      - id: "ai_content_q2"
        text: "How well integrated is AI content detection into your business processes?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No integration of AI content detection in business workflows"
          - "Ad-hoc checking of suspicious content when concerns arise"
          - "Regular scanning of key content and communications channels"
          - "Automated detection integrated into content management and publishing workflows"
          - "Comprehensive integration with real-time monitoring and policy enforcement"
        help_text: "Evaluate integration with email, social media, document management, and publishing systems"
      
      - id: "ai_content_q3"
        text: "How does your organization handle detected AI-generated content?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No established procedures for handling AI-generated content"
          - "Manual review and decision-making for flagged content"
          - "Defined policies with structured review and approval processes"
          - "Automated workflows with risk-based handling and escalation procedures"
          - "Comprehensive governance with automated policy enforcement and audit trails"
        help_text: "Consider policies for labeling, blocking, quarantine, and appropriate use of AI-generated content"

    indicators:
      indicators:
        - "Multi-modal AI-generated content detection capabilities"
        - "Integration with business workflows and content management"
        - "Real-time authentication and provenance tracking"
        - "Policy enforcement and governance frameworks"
        - "Accuracy and false positive management"
      
      definitions:
        level_1: "No tools or capabilities to detect AI-generated content"
        level_2: "Basic detection tools for obvious AI-generated text or simple media"
        level_3: "Advanced detection capabilities for sophisticated AI-generated content"
        level_4: "Multi-modal detection across text, images, audio, and video content"
        level_5: "Real-time authentication with provenance tracking and content verification"
      
      success_criteria:
        - "AI-generated content detection accuracy above 95% across all modalities"
        - "Integration with 100% of critical content workflows"
        - "Real-time detection with sub-second response times"
        - "Comprehensive audit trails and policy compliance tracking"

  deepfake_defense:
    id: "deepfake_defense"
    name: "Deepfake & Synthetic Media Defense"
    description: "Protection against deepfake attacks and synthetic media manipulation"
    pillar: "security_from_ai"
    weight: 1.3

    key_controls:
      - "Deepfake detection across multiple media types"
      - "Identity verification enhanced with liveness detection"
      - "Employee training on deepfake awareness"
      - "Incident procedures for deepfake attacks"
      - "Collaboration with industry on detection methods"
    
    levels:
      level_1:
        level: "level_1"
        name: "No Protection"
        description: "No protection against deepfake attacks"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Basic Tools"
        description: "Basic deepfake detection tools and awareness"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Automated Detection"
        description: "Automated deepfake detection in communications"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Advanced Verification"
        description: "Advanced synthetic media verification systems"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Comprehensive Defense"
        description: "Comprehensive synthetic media defense with real-time verification"
        score_value: 5
    
    questions:
      - id: "deepfake_defense_q1"
        text: "What defenses does your organization have against deepfake and synthetic media attacks?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No specific protection against deepfake or synthetic media attacks"
          - "Basic deepfake detection tools and employee awareness training"
          - "Automated deepfake detection integrated into communication systems"
          - "Advanced synthetic media verification with multi-factor authentication"
          - "Comprehensive defense including real-time verification and blockchain-based provenance"
        help_text: "Consider protection across video calls, emails, social media, and authentication systems"
      
      - id: "deepfake_defense_q2"
        text: "How well does your organization detect deepfakes in real-time communications?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No real-time deepfake detection capabilities"
          - "Manual verification procedures for suspicious video communications"
          - "Automated analysis of video calls with basic deepfake detection"
          - "Advanced real-time detection with confidence scoring and alerts"
          - "Comprehensive real-time verification with biometric and behavioral analysis"
        help_text: "Evaluate capabilities for video conferencing, voice calls, and live streaming verification"
      
      - id: "deepfake_defense_q3"
        text: "What procedures does your organization have for responding to deepfake incidents?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No established procedures for deepfake incident response"
          - "Basic incident response with manual investigation and containment"
          - "Structured response procedures with specialized deepfake analysis capabilities"
          - "Automated incident response with rapid containment and stakeholder notification"
          - "Comprehensive response including legal, forensic, and reputational damage mitigation"
        help_text: "Consider incident detection, analysis, containment, communication, and recovery procedures"

    indicators:
      indicators:
        - "Deepfake and synthetic media detection capabilities"
        - "Real-time verification in communications and media"
        - "Advanced authentication and provenance tracking"
        - "Incident response and containment procedures"
        - "Employee awareness and training programs"
      
      definitions:
        level_1: "No specific protection against deepfake or synthetic media attacks"
        level_2: "Basic deepfake detection tools and employee awareness training"
        level_3: "Automated deepfake detection integrated into communication systems"
        level_4: "Advanced synthetic media verification with multi-factor authentication"
        level_5: "Comprehensive defense with real-time verification and blockchain-based provenance"
      
      success_criteria:
        - "Deepfake detection accuracy above 98% in real-time communications"
        - "Incident response time reduced to under 15 minutes for critical deepfake threats"
        - "Employee training coverage achieving 100% completion rates"
        - "Integration with all communication and media platforms"

  ai_attack_defense:
    id: "ai_attack_defense"
    name: "AI-Powered Attack Defense"
    description: "Defense against AI-enabled attacks and social engineering"
    pillar: "security_from_ai"
    weight: 1.1

    key_controls:
      - "Defense mechanisms against adversarial attacks"
      - "Input preprocessing and sanitization for models"
      - "Model hardening and robustness techniques"
      - "Attack simulation and penetration testing"
      - "Defense-in-depth architecture for AI systems"
    
    levels:
      level_1:
        level: "level_1"
        name: "Reactive Response"
        description: "Reactive response to AI-enabled attacks"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Pattern Detection"
        description: "Detection of common AI attack patterns"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Proactive Defense"
        description: "Proactive defense against AI-powered social engineering"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Advanced Simulation"
        description: "Advanced AI attack simulation and defense testing"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Autonomous Defense"
        description: "Autonomous defense against evolving AI attack techniques"
        score_value: 5
    
    questions:
      - id: "ai_attack_defense_q1"
        text: "How well prepared is your organization to defend against AI-powered attacks?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "Reactive response only after AI-enabled attacks are detected"
          - "Basic detection capabilities for common AI attack patterns"
          - "Proactive defense strategies against known AI-powered social engineering"
          - "Advanced simulation and testing of defenses against AI attack scenarios"
          - "Autonomous defense systems that adapt to evolving AI attack techniques"
        help_text: "Consider defense against AI-generated phishing, social engineering, and automated attacks"
      
      - id: "ai_attack_defense_q2"
        text: "What training and awareness does your organization provide about AI-enabled threats?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No specific training on AI-enabled threats and attacks"
          - "Basic awareness materials about AI-generated phishing and social engineering"
          - "Regular training sessions with simulated AI attack scenarios"
          - "Comprehensive training program with role-specific AI threat education"
          - "Continuous adaptive training with real-time threat intelligence and personalized scenarios"
        help_text: "Evaluate training coverage across employees, security teams, and leadership"
      
      - id: "ai_attack_defense_q3"
        text: "How does your organization test and validate defenses against AI-powered attacks?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No specific testing of AI attack defense capabilities"
          - "Occasional tabletop exercises including AI attack scenarios"
          - "Regular red team exercises with simulated AI-powered attacks"
          - "Comprehensive testing with AI attack simulation platforms and tools"
          - "Continuous validation with autonomous red team AI and adaptive defense testing"
        help_text: "Consider penetration testing, red team exercises, and simulation of evolving AI attack techniques"

    indicators:
      indicators:
        - "AI-powered attack detection and pattern recognition"
        - "Proactive defense against AI-generated social engineering"
        - "Employee training and awareness programs for AI threats"
        - "AI attack simulation and defense testing capabilities"
        - "Autonomous defense systems and adaptive countermeasures"
      
      definitions:
        level_1: "Reactive response only after AI-enabled attacks are detected"
        level_2: "Basic detection capabilities for common AI attack patterns"
        level_3: "Proactive defense strategies against known AI-powered social engineering"
        level_4: "Advanced simulation and testing of defenses against AI attack scenarios"
        level_5: "Autonomous defense systems that adapt to evolving AI attack techniques"
      
      success_criteria:
        - "AI-powered attack detection accuracy above 90% with low false positives"
        - "Employee training effectiveness measured through simulated attack resistance"
        - "Regular defense testing against evolving AI attack techniques"
        - "Adaptive defense systems with real-time threat intelligence integration"

  prompt_injection_protection:
    id: "prompt_injection_protection"
    name: "Prompt Injection Protection"
    description: "Protection against direct and indirect prompt injection attacks and LLM manipulation through AI guardrails and security controls"
    pillar: "security_for_ai"
    weight: 1.1

    key_controls:
      - "Input validation and sanitization for direct prompt injections"
      - "Indirect injection protection for external content (documents, web pages, emails)"
      - "System prompt protection and encapsulation"
      - "AI guardrails for safety and security boundaries"
      - "Centralized guardrail policy management platform"
      - "Output filtering and content validation"
      - "Privilege separation for LLM actions and tool access"
      - "Real-time monitoring for injection attempts"
    
    framework_alignment:
      - indicator: "Direct and indirect prompt injection protection"
        frameworks:
          nist_ai_rmf: ["MAP 3.4", "MEASURE 2.7", "MANAGE 2.3"]
          iso_27001: ["A.14.2.1", "A.14.2.5", "A.12.6.1"]
          owasp_genai: ["LLM01:2025 Prompt Injection"]
      - indicator: "AI guardrails implementation and enforcement"
        frameworks:
          nist_ai_rmf: ["GOVERN 1.5", "MANAGE 2.2", "MEASURE 2.11"]
          iso_42001: ["7.2", "8.2"]
          owasp_genai: ["LLM01:2025 Prompt Injection", "LLM02:2025 Sensitive Information Disclosure"]
      - indicator: "Centralized guardrail policy management"
        frameworks:
          nist_ai_rmf: ["GOVERN 1.3", "GOVERN 2.2"]
          iso_27001: ["A.5.1.1", "A.18.1.1"]
          iso_42001: ["5.2", "6.1"]
      - indicator: "Input/output validation and filtering"
        frameworks:
          owasp_genai: ["LLM01:2025 Prompt Injection", "LLM02:2025 Sensitive Information Disclosure"]
          nist_ai_rmf: ["MEASURE 2.7", "MANAGE 2.3"]
      - indicator: "Monitoring and detection capabilities"
        frameworks:
          nist_ai_rmf: ["MEASURE 2.1", "MEASURE 4.2"]
          iso_27001: ["A.12.4.1", "A.16.1.2"]
    
    levels:
      level_1:
        level: "level_1"
        name: "No Awareness"
        description: "No awareness of prompt injection risks; no AI guardrails implemented"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Basic Validation"
        description: "Basic input validation for direct injections; ad-hoc guardrails per application"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Automated Detection"
        description: "Protection for direct and indirect injections; standardized AI guardrails with centralized policy definitions"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Advanced Protection"
        description: "Multi-layered guardrails with centralized policy management platform; automated detection and response for both injection types"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Comprehensive Security"
        description: "Adaptive AI guardrails with continuous learning; enterprise-wide centralized policy orchestration; zero-trust validation"
        score_value: 5
    
    questions:
      - id: "prompt_injection_q1"
        text: "What protections does your organization have against direct prompt injection attacks (malicious instructions in user prompts)?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No awareness or protection against direct prompt injections"
          - "Basic input validation and sanitization for user prompts"
          - "Automated detection and filtering of known direct injection patterns"
          - "Advanced guardrails with semantic analysis and automated blocking"
          - "Adaptive protections with continuous learning and behavioral analysis"
        help_text: "Direct injections occur when attackers craft malicious instructions directly in user prompts to manipulate LLM behavior"
      
      - id: "prompt_injection_q2"
        text: "What protections does your organization have against indirect prompt injection attacks (malicious instructions in external content)?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No awareness or protection against indirect prompt injections"
          - "Basic content filtering for external data sources"
          - "Content validation and source verification for external data"
          - "Multi-layered validation with context isolation and sandboxing"
          - "Comprehensive protection with content provenance tracking and zero-trust processing"
        help_text: "Indirect injections occur when attackers embed malicious instructions in external content that AI systems process (documents, web pages, emails, etc.)"
      
      - id: "prompt_injection_q3"
        text: "How mature is your organization's AI guardrail implementation?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No AI guardrails implemented"
          - "Ad-hoc guardrails implemented per application without standardization"
          - "Standardized guardrails with documented policies across applications"
          - "Centralized guardrail management platform with policy enforcement"
          - "Adaptive centralized guardrails with continuous learning and automatic policy updates"
        help_text: "AI guardrails are safety and security boundaries that prevent harmful outputs and behaviors across all AI systems"
      
      - id: "prompt_injection_q4"
        text: "Does your organization have a centralized AI guardrail policy management platform?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No centralized guardrail management"
          - "Planning or early implementation of centralized platform"
          - "Operational centralized platform with basic policy management"
          - "Advanced platform with automated policy deployment and monitoring"
          - "Fully integrated platform with AI-driven policy optimization and real-time adaptation"
        help_text: "A centralized platform enables consistent guardrail policy definition, deployment, monitoring, and enforcement across all AI applications"
      
      - id: "prompt_injection_q5"
        text: "How does your organization monitor and respond to prompt injection attempts?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No monitoring for prompt injection attempts"
          - "Basic logging of AI system interactions with manual review"
          - "Automated detection with alerting for suspicious prompt patterns"
          - "Real-time monitoring with automated blocking and incident response"
          - "Comprehensive threat intelligence with predictive detection and adaptive countermeasures"
        help_text: "Consider monitoring, logging, alerting, and incident response for both direct and indirect prompt injection attacks"

    indicators:
      indicators:
        - "Direct and indirect prompt injection protection"
        - "AI guardrails implementation and enforcement"
        - "Centralized guardrail policy management"
        - "Input/output validation and filtering"
        - "Monitoring and detection capabilities"
      
      definitions:
        level_1: "No awareness of prompt injection risks; no AI guardrails implemented"
        level_2: "Basic input validation for direct injections; ad-hoc guardrails per application"
        level_3: "Protection for direct and indirect injections; standardized AI guardrails with centralized policy definitions"
        level_4: "Multi-layered guardrails with centralized policy management platform; automated detection and response for both injection types"
        level_5: "Adaptive AI guardrails with continuous learning; enterprise-wide centralized policy orchestration; zero-trust validation"
      
      success_criteria:
        - "Prompt injection detection accuracy above 95% for both direct and indirect attacks"
        - "Comprehensive input validation across all AI interaction points and external content sources"
        - "Centralized guardrail policy management platform operational across all AI systems"
        - "Automated response and remediation for detected attacks with minimal false positives"
        - "Adaptive defenses that evolve with emerging prompt injection techniques"

  ai_supply_chain_security:
    id: "ai_supply_chain_security"
    name: "AI Supply Chain Security"
    description: "Security assessment and management of AI supply chain components"
    pillar: "security_from_ai"
    weight: 1.2

    key_controls:
      - "Vendor security assessment for AI providers"
      - "Model provenance verification and signing"
      - "Dataset source validation and integrity checks"
      - "Third-party model security review requirements"
      - "Supply chain risk monitoring and alerts"
    
    levels:
      level_1:
        level: "level_1"
        name: "No Vetting"
        description: "No vetting of AI models or training data"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Basic Checking"
        description: "Basic AI model provenance checking"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Comprehensive Assessment"
        description: "Comprehensive AI supply chain risk assessment"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Automated Verification"
        description: "Automated AI component security verification"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Continuous Monitoring"
        description: "Continuous AI supply chain threat monitoring"
        score_value: 5
    
    questions:
      - id: "ai_supply_chain_q1"
        text: "How does your organization assess the security of AI supply chain components?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No security assessment of AI models, datasets, or third-party AI services"
          - "Basic verification of AI model and data source provenance"
          - "Comprehensive risk assessment of AI supply chain components and vendors"
          - "Automated security verification with continuous monitoring of AI dependencies"
          - "End-to-end supply chain security with real-time threat intelligence and automated response"
        help_text: "Consider assessment of models, training data, AI APIs, libraries, and third-party AI services"
      
      - id: "ai_supply_chain_q2"
        text: "What controls does your organization have for AI model and data provenance?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No tracking of AI model or training data origins"
          - "Basic documentation of model sources and data lineage"
          - "Structured provenance tracking with verification of model integrity"
          - "Automated provenance verification with cryptographic signatures and audit trails"
          - "Comprehensive supply chain transparency with blockchain-based provenance and real-time verification"
        help_text: "Evaluate tracking of model origins, training data sources, and modification history"
      
      - id: "ai_supply_chain_q3"
        text: "How does your organization monitor for supply chain attacks targeting AI components?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No monitoring for AI supply chain attacks or compromised components"
          - "Basic threat intelligence monitoring for known AI supply chain vulnerabilities"
          - "Regular scanning and assessment of AI dependencies for security issues"
          - "Automated monitoring with threat detection and rapid response capabilities"
          - "Continuous threat intelligence with predictive analysis and proactive mitigation"
        help_text: "Consider monitoring for model poisoning, data corruption, and compromised AI services"

    indicators:
      indicators:
        - "AI supply chain component security assessment"
        - "Model and data provenance tracking and verification"
        - "Third-party AI service risk management"
        - "Automated security verification and monitoring"
        - "Supply chain threat intelligence and response"
      
      definitions:
        level_1: "No security assessment of AI models, datasets, or third-party AI services"
        level_2: "Basic verification of AI model and data source provenance"
        level_3: "Comprehensive risk assessment of AI supply chain components and vendors"
        level_4: "Automated security verification with continuous monitoring of AI dependencies"
        level_5: "End-to-end supply chain security with real-time threat intelligence and automated response"
      
      success_criteria:
        - "100% of AI supply chain components undergo security assessment"
        - "Complete provenance tracking for all AI models and training data"
        - "Automated threat detection for supply chain attacks"
        - "Comprehensive vendor risk management and compliance verification"

  adversarial_ai_defense:
    id: "adversarial_ai_defense"
    name: "Adversarial AI Defense"
    description: "Protection against adversarial AI attacks and model manipulation"
    pillar: "security_from_ai"
    weight: 1.0

    key_controls:
      - "Adversarial robustness testing methodology"
      - "Defense techniques: adversarial training, input certification"
      - "Monitoring for adversarial attack patterns"
      - "Model ensemble and diversity strategies"
      - "Regular adversarial red team exercises"
    
    levels:
      level_1:
        level: "level_1"
        name: "No Protection"
        description: "No protection against adversarial AI attacks"
        score_value: 1
      level_2:
        level: "level_2"
        name: "Basic Understanding"
        description: "Basic understanding of adversarial techniques"
        score_value: 2
      level_3:
        level: "level_3"
        name: "Robustness Testing"
        description: "Adversarial robustness testing and hardening"
        score_value: 3
      level_4:
        level: "level_4"
        name: "Advanced Defenses"
        description: "Advanced adversarial defense mechanisms"
        score_value: 4
      level_5:
        level: "level_5"
        name: "Adaptive Defense"
        description: "Adaptive adversarial AI defense with continuous evolution"
        score_value: 5
    
    questions:
      - id: "adversarial_ai_q1"
        text: "What defenses does your organization have against adversarial AI attacks?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No specific protection against adversarial AI attacks or model manipulation"
          - "Basic understanding of adversarial techniques with some awareness training"
          - "Adversarial robustness testing and model hardening practices"
          - "Advanced defense mechanisms including adversarial training and detection"
          - "Adaptive defense systems with continuous evolution and autonomous protection"
        help_text: "Consider protection against model poisoning, evasion attacks, and adversarial examples"
      
      - id: "adversarial_ai_q2"
        text: "How does your organization test AI models for adversarial robustness?"
        question_type: "single_choice"
        weight: 1.0
        required: true
        options:
          - "No adversarial robustness testing of AI models"
          - "Basic testing with simple adversarial examples"
          - "Systematic testing with known adversarial attack methods"
          - "Comprehensive testing including sophisticated attack simulations"
          - "Continuous adversarial testing with automated red team AI systems"
        help_text: "Evaluate testing for evasion attacks, model inversion, and membership inference attacks"
      
      - id: "adversarial_ai_q3"
        text: "How does your organization detect and respond to adversarial attacks in production?"
        question_type: "single_choice"
        weight: 0.9
        required: true
        options:
          - "No detection or response capabilities for adversarial attacks"
          - "Basic monitoring with manual investigation of anomalous model behavior"
          - "Automated detection of known adversarial patterns with alerting"
          - "Real-time detection with automated response and model protection measures"
          - "Comprehensive defense with predictive detection and adaptive countermeasures"
        help_text: "Consider monitoring, anomaly detection, incident response, and model recovery procedures"

    indicators:
      indicators:
        - "Adversarial robustness testing and validation"
        - "Advanced defense mechanisms and adversarial training"
        - "Real-time detection and monitoring capabilities"
        - "Incident response and model recovery procedures"
        - "Adaptive defense systems and continuous evolution"
      
      definitions:
        level_1: "No specific protection against adversarial AI attacks or model manipulation"
        level_2: "Basic understanding of adversarial techniques with some awareness training"
        level_3: "Adversarial robustness testing and model hardening practices"
        level_4: "Advanced defense mechanisms including adversarial training and detection"
        level_5: "Adaptive defense systems with continuous evolution and autonomous protection"
      
      success_criteria:
        - "Adversarial robustness testing for 100% of production AI models"
        - "Real-time detection accuracy above 95% for adversarial attacks"
        - "Automated incident response with model recovery capabilities"
        - "Continuous defense evolution with adaptive countermeasures"
